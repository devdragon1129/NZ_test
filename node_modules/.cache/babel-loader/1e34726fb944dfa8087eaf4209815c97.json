{"ast":null,"code":"'use strict';\n\nvar extend = require('deep-extend');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar pull = require('pull-stream/pull');\n\nvar values = require('pull-stream/sources/values');\n\nvar collect = require('pull-stream/sinks/collect');\n\nvar through = require('pull-stream/throughs/through');\n\nvar pullThrough = require('pull-through');\n\nvar parallel = require('async/parallel');\n\nvar waterfall = require('async/waterfall');\n\nvar paraMap = require('pull-paramap');\n\nvar persist = require('../utils/persist');\n\nvar reduce = require('./reduce');\n\nvar _require = require('ipld-dag-pb'),\n    DAGNode = _require.DAGNode;\n\nvar defaultOptions = {\n  chunkerOptions: {\n    maxChunkSize: 262144,\n    avgChunkSize: 262144\n  },\n  rawLeaves: false,\n  hashAlg: 'sha2-256',\n  leafType: 'file',\n  cidVersion: 0,\n  progress: function progress() {}\n};\n\nmodule.exports = function builder(createChunker, ipld, createReducer, _options) {\n  var options = extend({}, defaultOptions, _options);\n  options.progress = typeof options.progress === 'function' ? options.progress : defaultOptions.progress;\n  return function (source) {\n    return function (items, cb) {\n      parallel(items.map(function (item) {\n        return function (cb) {\n          if (!item.content) {\n            // item is a directory\n            return createAndStoreDir(item, function (err, node) {\n              if (err) {\n                return cb(err);\n              }\n\n              if (node) {\n                source.push(node);\n              }\n\n              cb();\n            });\n          } // item is a file\n\n\n          createAndStoreFile(item, function (err, node) {\n            if (err) {\n              return cb(err);\n            }\n\n            if (node) {\n              source.push(node);\n            }\n\n            cb();\n          });\n        };\n      }), cb);\n    };\n  };\n\n  function createAndStoreDir(item, callback) {\n    // 1. create the empty dir dag node\n    // 2. write it to the dag store\n    var d = new UnixFS('directory');\n    waterfall([function (cb) {\n      return DAGNode.create(d.marshal(), [], cb);\n    }, function (node, cb) {\n      return persist(node, ipld, options, cb);\n    }], function (err, result) {\n      if (err) {\n        return callback(err);\n      }\n\n      callback(null, {\n        path: item.path,\n        multihash: result.cid.buffer,\n        size: result.node.size\n      });\n    });\n  }\n\n  function createAndStoreFile(file, callback) {\n    if (Buffer.isBuffer(file.content)) {\n      file.content = values([file.content]);\n    }\n\n    if (typeof file.content !== 'function') {\n      return callback(new Error('invalid content'));\n    }\n\n    var reducer = createReducer(reduce(file, ipld, options), options);\n    var chunker;\n\n    try {\n      chunker = createChunker(options.chunkerOptions);\n    } catch (error) {\n      return callback(error);\n    }\n\n    var previous;\n    var count = 0;\n    pull(file.content, chunker, through(function (buffer) {\n      options.progress(buffer.length);\n    }), paraMap(function (buffer, callback) {\n      waterfall([function (cb) {\n        if (options.rawLeaves) {\n          return cb(null, {\n            size: buffer.length,\n            leafSize: buffer.length,\n            data: buffer\n          });\n        }\n\n        var file = new UnixFS(options.leafType, buffer);\n        DAGNode.create(file.marshal(), [], function (err, node) {\n          if (err) {\n            return cb(err);\n          }\n\n          cb(null, {\n            size: node.size,\n            leafSize: file.fileSize(),\n            data: node\n          });\n        });\n      }, function (leaf, cb) {\n        persist(leaf.data, ipld, options, function (error, results) {\n          if (error) {\n            return cb(error);\n          }\n\n          cb(null, {\n            size: leaf.size,\n            leafSize: leaf.leafSize,\n            data: results.node,\n            multihash: results.cid.buffer,\n            path: leaf.path,\n            name: ''\n          });\n        });\n      }], callback);\n    }), pullThrough( // mark as single node if only one single node\n    function onData(data) {\n      count++;\n\n      if (previous) {\n        this.queue(previous);\n      }\n\n      previous = data;\n    }, function ended() {\n      if (previous) {\n        if (count === 1) {\n          previous.single = true;\n        }\n\n        this.queue(previous);\n      }\n\n      this.queue(null);\n    }), reducer, collect(function (err, roots) {\n      if (err) {\n        callback(err);\n      } else {\n        callback(null, roots[0]);\n      }\n    }));\n  }\n};","map":null,"metadata":{},"sourceType":"script"}