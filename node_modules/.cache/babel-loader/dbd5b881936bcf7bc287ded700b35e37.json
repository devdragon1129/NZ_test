{"ast":null,"code":"import { __decorate, __extends } from \"tslib\";\nimport { serialize, serializeAsTexture, SerializationHelper } from \"../../../Misc/decorators\";\nimport { Logger } from \"../../../Misc/logger\";\nimport { Vector2, Vector3, Matrix, Vector4 } from \"../../../Maths/math.vector\";\nimport { Scalar } from \"../../../Maths/math.scalar\";\nimport { Texture } from \"../../../Materials/Textures/texture\";\nimport { PostProcess } from \"../../../PostProcesses/postProcess\";\nimport { PostProcessRenderPipeline } from \"../../../PostProcesses/RenderPipeline/postProcessRenderPipeline\";\nimport { PostProcessRenderEffect } from \"../../../PostProcesses/RenderPipeline/postProcessRenderEffect\";\nimport { BlurPostProcess } from \"../../../PostProcesses/blurPostProcess\";\nimport { FxaaPostProcess } from \"../../../PostProcesses/fxaaPostProcess\";\nimport { _TypeStore } from '../../../Misc/typeStore';\nimport { MotionBlurPostProcess } from \"../../motionBlurPostProcess\";\nimport { ScreenSpaceReflectionPostProcess } from \"../../screenSpaceReflectionPostProcess\";\nimport \"../../../PostProcesses/RenderPipeline/postProcessRenderPipelineManagerSceneComponent\";\nimport \"../../../Shaders/standard.fragment\";\n/**\r\n * Standard rendering pipeline\r\n * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.\r\n * @see https://doc.babylonjs.com/how_to/using_standard_rendering_pipeline\r\n */\n\nvar StandardRenderingPipeline =\n/** @class */\nfunction (_super) {\n  __extends(StandardRenderingPipeline, _super);\n  /**\r\n   * Default pipeline should be used going forward but the standard pipeline will be kept for backwards compatibility.\r\n   * @constructor\r\n   * @param name The rendering pipeline name\r\n   * @param scene The scene linked to this pipeline\r\n   * @param ratio The size of the postprocesses (0.5 means that your postprocess will have a width = canvas.width 0.5 and a height = canvas.height 0.5)\r\n   * @param originalPostProcess the custom original color post-process. Must be \"reusable\". Can be null.\r\n   * @param cameras The array of cameras that the rendering pipeline will be attached to\r\n   */\n\n\n  function StandardRenderingPipeline(name, scene, ratio, originalPostProcess, cameras) {\n    if (originalPostProcess === void 0) {\n      originalPostProcess = null;\n    }\n\n    var _this = _super.call(this, scene.getEngine(), name) || this;\n    /**\r\n     * Post-process used to down scale an image x4\r\n     */\n\n\n    _this.downSampleX4PostProcess = null;\n    /**\r\n     * Post-process used to calculate the illuminated surfaces controlled by a threshold\r\n     */\n\n    _this.brightPassPostProcess = null;\n    /**\r\n     * Post-process array storing all the horizontal blur post-processes used by the pipeline\r\n     */\n\n    _this.blurHPostProcesses = [];\n    /**\r\n     * Post-process array storing all the vertical blur post-processes used by the pipeline\r\n     */\n\n    _this.blurVPostProcesses = [];\n    /**\r\n     * Post-process used to add colors of 2 textures (typically brightness + real scene color)\r\n     */\n\n    _this.textureAdderPostProcess = null;\n    /**\r\n     * Post-process used to create volumetric lighting effect\r\n     */\n\n    _this.volumetricLightPostProcess = null;\n    /**\r\n     * Post-process used to smooth the previous volumetric light post-process on the X axis\r\n     */\n\n    _this.volumetricLightSmoothXPostProcess = null;\n    /**\r\n     * Post-process used to smooth the previous volumetric light post-process on the Y axis\r\n     */\n\n    _this.volumetricLightSmoothYPostProcess = null;\n    /**\r\n     * Post-process used to merge the volumetric light effect and the real scene color\r\n     */\n\n    _this.volumetricLightMergePostProces = null;\n    /**\r\n     * Post-process used to store the final volumetric light post-process (attach/detach for debug purpose)\r\n     */\n\n    _this.volumetricLightFinalPostProcess = null;\n    /**\r\n     * Base post-process used to calculate the average luminance of the final image for HDR\r\n     */\n\n    _this.luminancePostProcess = null;\n    /**\r\n     * Post-processes used to create down sample post-processes in order to get\r\n     * the average luminance of the final image for HDR\r\n     * Array of length \"StandardRenderingPipeline.LuminanceSteps\"\r\n     */\n\n    _this.luminanceDownSamplePostProcesses = [];\n    /**\r\n     * Post-process used to create a HDR effect (light adaptation)\r\n     */\n\n    _this.hdrPostProcess = null;\n    /**\r\n     * Post-process used to store the final texture adder post-process (attach/detach for debug purpose)\r\n     */\n\n    _this.textureAdderFinalPostProcess = null;\n    /**\r\n     * Post-process used to store the final lens flare post-process (attach/detach for debug purpose)\r\n     */\n\n    _this.lensFlareFinalPostProcess = null;\n    /**\r\n     * Post-process used to merge the final HDR post-process and the real scene color\r\n     */\n\n    _this.hdrFinalPostProcess = null;\n    /**\r\n     * Post-process used to create a lens flare effect\r\n     */\n\n    _this.lensFlarePostProcess = null;\n    /**\r\n     * Post-process that merges the result of the lens flare post-process and the real scene color\r\n     */\n\n    _this.lensFlareComposePostProcess = null;\n    /**\r\n     * Post-process used to create a motion blur effect\r\n     */\n\n    _this.motionBlurPostProcess = null;\n    /**\r\n     * Post-process used to create a depth of field effect\r\n     */\n\n    _this.depthOfFieldPostProcess = null;\n    /**\r\n     * The Fast Approximate Anti-Aliasing post process which attemps to remove aliasing from an image.\r\n     */\n\n    _this.fxaaPostProcess = null;\n    /**\r\n     * Post-process used to simulate realtime reflections using the screen space and geometry renderer.\r\n     */\n\n    _this.screenSpaceReflectionPostProcess = null; // Values\n\n    /**\r\n     * Represents the brightness threshold in order to configure the illuminated surfaces\r\n     */\n\n    _this.brightThreshold = 1.0;\n    /**\r\n     * Configures the blur intensity used for surexposed surfaces are highlighted surfaces (light halo)\r\n     */\n\n    _this.blurWidth = 512.0;\n    /**\r\n     * Sets if the blur for highlighted surfaces must be only horizontal\r\n     */\n\n    _this.horizontalBlur = false;\n    /**\r\n     * Texture used typically to simulate \"dirty\" on camera lens\r\n     */\n\n    _this.lensTexture = null;\n    /**\r\n     * Represents the offset coefficient based on Rayleigh principle. Typically in interval [-0.2, 0.2]\r\n     */\n\n    _this.volumetricLightCoefficient = 0.2;\n    /**\r\n     * The overall power of volumetric lights, typically in interval [0, 10] maximum\r\n     */\n\n    _this.volumetricLightPower = 4.0;\n    /**\r\n     * Used the set the blur intensity to smooth the volumetric lights\r\n     */\n\n    _this.volumetricLightBlurScale = 64.0;\n    /**\r\n     * Light (spot or directional) used to generate the volumetric lights rays\r\n     * The source light must have a shadow generate so the pipeline can get its\r\n     * depth map\r\n     */\n\n    _this.sourceLight = null;\n    /**\r\n     * For eye adaptation, represents the minimum luminance the eye can see\r\n     */\n\n    _this.hdrMinimumLuminance = 1.0;\n    /**\r\n     * For eye adaptation, represents the decrease luminance speed\r\n     */\n\n    _this.hdrDecreaseRate = 0.5;\n    /**\r\n     * For eye adaptation, represents the increase luminance speed\r\n     */\n\n    _this.hdrIncreaseRate = 0.5;\n    /**\r\n     * Lens color texture used by the lens flare effect. Mandatory if lens flare effect enabled\r\n     */\n\n    _this.lensColorTexture = null;\n    /**\r\n     * The overall strengh for the lens flare effect\r\n     */\n\n    _this.lensFlareStrength = 20.0;\n    /**\r\n     * Dispersion coefficient for lens flare ghosts\r\n     */\n\n    _this.lensFlareGhostDispersal = 1.4;\n    /**\r\n     * Main lens flare halo width\r\n     */\n\n    _this.lensFlareHaloWidth = 0.7;\n    /**\r\n     * Based on the lens distortion effect, defines how much the lens flare result\r\n     * is distorted\r\n     */\n\n    _this.lensFlareDistortionStrength = 16.0;\n    /**\r\n     * Configures the blur intensity used for for lens flare (halo)\r\n     */\n\n    _this.lensFlareBlurWidth = 512.0;\n    /**\r\n     * Lens star texture must be used to simulate rays on the flares and is available\r\n     * in the documentation\r\n     */\n\n    _this.lensStarTexture = null;\n    /**\r\n     * As the \"lensTexture\" (can be the same texture or different), it is used to apply the lens\r\n     * flare effect by taking account of the dirt texture\r\n     */\n\n    _this.lensFlareDirtTexture = null;\n    /**\r\n     * Represents the focal length for the depth of field effect\r\n     */\n\n    _this.depthOfFieldDistance = 10.0;\n    /**\r\n     * Represents the blur intensity for the blurred part of the depth of field effect\r\n     */\n\n    _this.depthOfFieldBlurWidth = 64.0;\n    /**\r\n     * List of animations for the pipeline (IAnimatable implementation)\r\n     */\n\n    _this.animations = [];\n    _this._currentDepthOfFieldSource = null;\n    _this._fixedExposure = 1.0;\n    _this._currentExposure = 1.0;\n    _this._hdrAutoExposure = false;\n    _this._hdrCurrentLuminance = 1.0;\n    _this._motionStrength = 1.0;\n    _this._isObjectBasedMotionBlur = false;\n    _this._camerasToBeAttached = []; // Getters and setters\n\n    _this._bloomEnabled = false;\n    _this._depthOfFieldEnabled = false;\n    _this._vlsEnabled = false;\n    _this._lensFlareEnabled = false;\n    _this._hdrEnabled = false;\n    _this._motionBlurEnabled = false;\n    _this._fxaaEnabled = false;\n    _this._screenSpaceReflectionsEnabled = false;\n    _this._motionBlurSamples = 64.0;\n    _this._volumetricLightStepsCount = 50.0;\n    _this._samples = 1;\n    _this._cameras = cameras || scene.cameras;\n    _this._cameras = _this._cameras.slice();\n    _this._camerasToBeAttached = _this._cameras.slice(); // Initialize\n\n    _this._scene = scene;\n    _this._basePostProcess = originalPostProcess;\n    _this._ratio = ratio; // Misc\n\n    _this._floatTextureType = scene.getEngine().getCaps().textureFloatRender ? 1 : 2; // Finish\n\n    scene.postProcessRenderPipelineManager.addPipeline(_this);\n\n    _this._buildPipeline();\n\n    return _this;\n  }\n\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"exposure\", {\n    /**\r\n     * Gets the overall exposure used by the pipeline\r\n     */\n    get: function get() {\n      return this._fixedExposure;\n    },\n\n    /**\r\n     * Sets the overall exposure used by the pipeline\r\n     */\n    set: function set(value) {\n      this._fixedExposure = value;\n      this._currentExposure = value;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"hdrAutoExposure\", {\n    /**\r\n     * Gets wether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process\r\n     */\n    get: function get() {\n      return this._hdrAutoExposure;\n    },\n\n    /**\r\n     * Sets wether or not the exposure of the overall pipeline should be automatically adjusted by the HDR post-process\r\n     */\n    set: function set(value) {\n      this._hdrAutoExposure = value;\n\n      if (this.hdrPostProcess) {\n        var defines = [\"#define HDR\"];\n\n        if (value) {\n          defines.push(\"#define AUTO_EXPOSURE\");\n        }\n\n        this.hdrPostProcess.updateEffect(defines.join(\"\\n\"));\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"motionStrength\", {\n    /**\r\n     * Gets how much the image is blurred by the movement while using the motion blur post-process\r\n     */\n    get: function get() {\n      return this._motionStrength;\n    },\n\n    /**\r\n     * Sets how much the image is blurred by the movement while using the motion blur post-process\r\n     */\n    set: function set(strength) {\n      this._motionStrength = strength;\n\n      if (this._isObjectBasedMotionBlur && this.motionBlurPostProcess) {\n        this.motionBlurPostProcess.motionStrength = strength;\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"objectBasedMotionBlur\", {\n    /**\r\n     * Gets wether or not the motion blur post-process is object based or screen based.\r\n     */\n    get: function get() {\n      return this._isObjectBasedMotionBlur;\n    },\n\n    /**\r\n     * Sets wether or not the motion blur post-process should be object based or screen based\r\n     */\n    set: function set(value) {\n      var shouldRebuild = this._isObjectBasedMotionBlur !== value;\n      this._isObjectBasedMotionBlur = value;\n\n      if (shouldRebuild) {\n        this._buildPipeline();\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"BloomEnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the bloom pipeline is enabled\r\n     */\n    get: function get() {\n      return this._bloomEnabled;\n    },\n    set: function set(enabled) {\n      if (this._bloomEnabled === enabled) {\n        return;\n      }\n\n      this._bloomEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"DepthOfFieldEnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the depth of field pipeline is enabed\r\n     */\n    get: function get() {\n      return this._depthOfFieldEnabled;\n    },\n    set: function set(enabled) {\n      if (this._depthOfFieldEnabled === enabled) {\n        return;\n      }\n\n      this._depthOfFieldEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"LensFlareEnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the lens flare pipeline is enabed\r\n     */\n    get: function get() {\n      return this._lensFlareEnabled;\n    },\n    set: function set(enabled) {\n      if (this._lensFlareEnabled === enabled) {\n        return;\n      }\n\n      this._lensFlareEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"HDREnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the HDR pipeline is enabled\r\n     */\n    get: function get() {\n      return this._hdrEnabled;\n    },\n    set: function set(enabled) {\n      if (this._hdrEnabled === enabled) {\n        return;\n      }\n\n      this._hdrEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"VLSEnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the volumetric lights scattering effect is enabled\r\n     */\n    get: function get() {\n      return this._vlsEnabled;\n    },\n    set: function set(enabled) {\n      if (this._vlsEnabled === enabled) {\n        return;\n      }\n\n      if (enabled) {\n        var geometry = this._scene.enableGeometryBufferRenderer();\n\n        if (!geometry) {\n          Logger.Warn(\"Geometry renderer is not supported, cannot create volumetric lights in Standard Rendering Pipeline\");\n          return;\n        }\n      }\n\n      this._vlsEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"MotionBlurEnabled\", {\n    /**\r\n     * @ignore\r\n     * Specifies if the motion blur effect is enabled\r\n     */\n    get: function get() {\n      return this._motionBlurEnabled;\n    },\n    set: function set(enabled) {\n      if (this._motionBlurEnabled === enabled) {\n        return;\n      }\n\n      this._motionBlurEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"fxaaEnabled\", {\n    /**\r\n     * Specifies if anti-aliasing is enabled\r\n     */\n    get: function get() {\n      return this._fxaaEnabled;\n    },\n    set: function set(enabled) {\n      if (this._fxaaEnabled === enabled) {\n        return;\n      }\n\n      this._fxaaEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"screenSpaceReflectionsEnabled\", {\n    /**\r\n     * Specifies if screen space reflections are enabled.\r\n     */\n    get: function get() {\n      return this._screenSpaceReflectionsEnabled;\n    },\n    set: function set(enabled) {\n      if (this._screenSpaceReflectionsEnabled === enabled) {\n        return;\n      }\n\n      this._screenSpaceReflectionsEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"volumetricLightStepsCount\", {\n    /**\r\n     * Specifies the number of steps used to calculate the volumetric lights\r\n     * Typically in interval [50, 200]\r\n     */\n    get: function get() {\n      return this._volumetricLightStepsCount;\n    },\n    set: function set(count) {\n      if (this.volumetricLightPostProcess) {\n        this.volumetricLightPostProcess.updateEffect(\"#define VLS\\n#define NB_STEPS \" + count.toFixed(1));\n      }\n\n      this._volumetricLightStepsCount = count;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"motionBlurSamples\", {\n    /**\r\n     * Specifies the number of samples used for the motion blur effect\r\n     * Typically in interval [16, 64]\r\n     */\n    get: function get() {\n      return this._motionBlurSamples;\n    },\n    set: function set(samples) {\n      if (this.motionBlurPostProcess) {\n        if (this._isObjectBasedMotionBlur) {\n          this.motionBlurPostProcess.motionBlurSamples = samples;\n        } else {\n          this.motionBlurPostProcess.updateEffect(\"#define MOTION_BLUR\\n#define MAX_MOTION_SAMPLES \" + samples.toFixed(1));\n        }\n      }\n\n      this._motionBlurSamples = samples;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(StandardRenderingPipeline.prototype, \"samples\", {\n    /**\r\n     * Specifies MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)\r\n     */\n    get: function get() {\n      return this._samples;\n    },\n    set: function set(sampleCount) {\n      if (this._samples === sampleCount) {\n        return;\n      }\n\n      this._samples = sampleCount;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  StandardRenderingPipeline.prototype._buildPipeline = function () {\n    var _this = this;\n\n    var ratio = this._ratio;\n    var scene = this._scene;\n\n    this._disposePostProcesses();\n\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras); // get back cameras to be used to reattach pipeline\n\n\n      this._cameras = this._camerasToBeAttached.slice();\n    }\n\n    this._reset(); // Create pass post-process\n\n\n    if (this._screenSpaceReflectionsEnabled) {\n      this.screenSpaceReflectionPostProcess = new ScreenSpaceReflectionPostProcess(\"HDRPass\", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n      this.screenSpaceReflectionPostProcess.onApplyObservable.add(function () {\n        _this._currentDepthOfFieldSource = _this.screenSpaceReflectionPostProcess;\n      });\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRScreenSpaceReflections\", function () {\n        return _this.screenSpaceReflectionPostProcess;\n      }, true));\n    }\n\n    if (!this._basePostProcess) {\n      this.originalPostProcess = new PostProcess(\"HDRPass\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", this._floatTextureType);\n    } else {\n      this.originalPostProcess = this._basePostProcess;\n    }\n\n    this.originalPostProcess.autoClear = !this.screenSpaceReflectionPostProcess;\n    this.originalPostProcess.onApplyObservable.add(function () {\n      _this._currentDepthOfFieldSource = _this.originalPostProcess;\n    });\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPassPostProcess\", function () {\n      return _this.originalPostProcess;\n    }, true));\n\n    if (this._bloomEnabled) {\n      // Create down sample X4 post-process\n      this._createDownSampleX4PostProcess(scene, ratio / 4); // Create bright pass post-process\n\n\n      this._createBrightPassPostProcess(scene, ratio / 4); // Create gaussian blur post-processes (down sampling blurs)\n\n\n      this._createBlurPostProcesses(scene, ratio / 4, 1); // Create texture adder post-process\n\n\n      this._createTextureAdderPostProcess(scene, ratio); // Create depth-of-field source post-process\n\n\n      this.textureAdderFinalPostProcess = new PostProcess(\"HDRDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBaseDepthOfFieldSource\", function () {\n        return _this.textureAdderFinalPostProcess;\n      }, true));\n    }\n\n    if (this._vlsEnabled) {\n      // Create volumetric light\n      this._createVolumetricLightPostProcess(scene, ratio); // Create volumetric light final post-process\n\n\n      this.volumetricLightFinalPostProcess = new PostProcess(\"HDRVLSFinal\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLSFinal\", function () {\n        return _this.volumetricLightFinalPostProcess;\n      }, true));\n    }\n\n    if (this._lensFlareEnabled) {\n      // Create lens flare post-process\n      this._createLensFlarePostProcess(scene, ratio); // Create depth-of-field source post-process post lens-flare and disable it now\n\n\n      this.lensFlareFinalPostProcess = new PostProcess(\"HDRPostLensFlareDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPostLensFlareDepthOfFieldSource\", function () {\n        return _this.lensFlareFinalPostProcess;\n      }, true));\n    }\n\n    if (this._hdrEnabled) {\n      // Create luminance\n      this._createLuminancePostProcesses(scene, this._floatTextureType); // Create HDR\n\n\n      this._createHdrPostProcess(scene, ratio); // Create depth-of-field source post-process post hdr and disable it now\n\n\n      this.hdrFinalPostProcess = new PostProcess(\"HDRPostHDReDepthOfFieldSource\", \"standard\", [], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define PASS_POST_PROCESS\", 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRPostHDReDepthOfFieldSource\", function () {\n        return _this.hdrFinalPostProcess;\n      }, true));\n    }\n\n    if (this._depthOfFieldEnabled) {\n      // Create gaussian blur used by depth-of-field\n      this._createBlurPostProcesses(scene, ratio / 2, 3, \"depthOfFieldBlurWidth\"); // Create depth-of-field post-process\n\n\n      this._createDepthOfFieldPostProcess(scene, ratio);\n    }\n\n    if (this._motionBlurEnabled) {\n      // Create motion blur post-process\n      this._createMotionBlurPostProcess(scene, ratio);\n    }\n\n    if (this._fxaaEnabled) {\n      // Create fxaa post-process\n      this.fxaaPostProcess = new FxaaPostProcess(\"fxaa\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);\n      this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRFxaa\", function () {\n        return _this.fxaaPostProcess;\n      }, true));\n    }\n\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n    }\n\n    if (!this._enableMSAAOnFirstPostProcess(this._samples) && this._samples > 1) {\n      Logger.Warn(\"MSAA failed to enable, MSAA is only supported in browsers that support webGL >= 2.0\");\n    }\n  }; // Down Sample X4 Post-Processs\n\n\n  StandardRenderingPipeline.prototype._createDownSampleX4PostProcess = function (scene, ratio) {\n    var _this = this;\n\n    var downSampleX4Offsets = new Array(32);\n    this.downSampleX4PostProcess = new PostProcess(\"HDRDownSampleX4\", \"standard\", [\"dsOffsets\"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define DOWN_SAMPLE_X4\", this._floatTextureType);\n\n    this.downSampleX4PostProcess.onApply = function (effect) {\n      var id = 0;\n      var width = _this.downSampleX4PostProcess.width;\n      var height = _this.downSampleX4PostProcess.height;\n\n      for (var i = -2; i < 2; i++) {\n        for (var j = -2; j < 2; j++) {\n          downSampleX4Offsets[id] = (i + 0.5) * (1.0 / width);\n          downSampleX4Offsets[id + 1] = (j + 0.5) * (1.0 / height);\n          id += 2;\n        }\n      }\n\n      effect.setArray2(\"dsOffsets\", downSampleX4Offsets);\n    }; // Add to pipeline\n\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRDownSampleX4\", function () {\n      return _this.downSampleX4PostProcess;\n    }, true));\n  }; // Brightpass Post-Process\n\n\n  StandardRenderingPipeline.prototype._createBrightPassPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    var brightOffsets = new Array(8);\n    this.brightPassPostProcess = new PostProcess(\"HDRBrightPass\", \"standard\", [\"dsOffsets\", \"brightThreshold\"], [], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define BRIGHT_PASS\", this._floatTextureType);\n\n    this.brightPassPostProcess.onApply = function (effect) {\n      var sU = 1.0 / _this.brightPassPostProcess.width;\n      var sV = 1.0 / _this.brightPassPostProcess.height;\n      brightOffsets[0] = -0.5 * sU;\n      brightOffsets[1] = 0.5 * sV;\n      brightOffsets[2] = 0.5 * sU;\n      brightOffsets[3] = 0.5 * sV;\n      brightOffsets[4] = -0.5 * sU;\n      brightOffsets[5] = -0.5 * sV;\n      brightOffsets[6] = 0.5 * sU;\n      brightOffsets[7] = -0.5 * sV;\n      effect.setArray2(\"dsOffsets\", brightOffsets);\n      effect.setFloat(\"brightThreshold\", _this.brightThreshold);\n    }; // Add to pipeline\n\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBrightPass\", function () {\n      return _this.brightPassPostProcess;\n    }, true));\n  }; // Create blur H&V post-processes\n\n\n  StandardRenderingPipeline.prototype._createBlurPostProcesses = function (scene, ratio, indice, blurWidthKey) {\n    var _this = this;\n\n    if (blurWidthKey === void 0) {\n      blurWidthKey = \"blurWidth\";\n    }\n\n    var engine = scene.getEngine();\n    var blurX = new BlurPostProcess(\"HDRBlurH\" + \"_\" + indice, new Vector2(1, 0), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n    var blurY = new BlurPostProcess(\"HDRBlurV\" + \"_\" + indice, new Vector2(0, 1), this[blurWidthKey], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, this._floatTextureType);\n    blurX.onActivateObservable.add(function () {\n      var dw = blurX.width / engine.getRenderWidth();\n      blurX.kernel = _this[blurWidthKey] * dw;\n    });\n    blurY.onActivateObservable.add(function () {\n      var dw = blurY.height / engine.getRenderHeight();\n      blurY.kernel = _this.horizontalBlur ? 64 * dw : _this[blurWidthKey] * dw;\n    });\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBlurH\" + indice, function () {\n      return blurX;\n    }, true));\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRBlurV\" + indice, function () {\n      return blurY;\n    }, true));\n    this.blurHPostProcesses.push(blurX);\n    this.blurVPostProcesses.push(blurY);\n  }; // Create texture adder post-process\n\n\n  StandardRenderingPipeline.prototype._createTextureAdderPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    this.textureAdderPostProcess = new PostProcess(\"HDRTextureAdder\", \"standard\", [\"exposure\"], [\"otherSampler\", \"lensSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define TEXTURE_ADDER\", this._floatTextureType);\n\n    this.textureAdderPostProcess.onApply = function (effect) {\n      effect.setTextureFromPostProcess(\"otherSampler\", _this._vlsEnabled ? _this._currentDepthOfFieldSource : _this.originalPostProcess);\n      effect.setTexture(\"lensSampler\", _this.lensTexture);\n      effect.setFloat(\"exposure\", _this._currentExposure);\n      _this._currentDepthOfFieldSource = _this.textureAdderFinalPostProcess;\n    }; // Add to pipeline\n\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRTextureAdder\", function () {\n      return _this.textureAdderPostProcess;\n    }, true));\n  };\n\n  StandardRenderingPipeline.prototype._createVolumetricLightPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    var geometryRenderer = scene.enableGeometryBufferRenderer();\n    geometryRenderer.enablePosition = true;\n    var geometry = geometryRenderer.getGBuffer(); // Base post-process\n\n    this.volumetricLightPostProcess = new PostProcess(\"HDRVLS\", \"standard\", [\"shadowViewProjection\", \"cameraPosition\", \"sunDirection\", \"sunColor\", \"scatteringCoefficient\", \"scatteringPower\", \"depthValues\"], [\"shadowMapSampler\", \"positionSampler\"], ratio / 8, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define VLS\\n#define NB_STEPS \" + this._volumetricLightStepsCount.toFixed(1));\n    var depthValues = Vector2.Zero();\n\n    this.volumetricLightPostProcess.onApply = function (effect) {\n      if (_this.sourceLight && _this.sourceLight.getShadowGenerator() && _this._scene.activeCamera) {\n        var generator = _this.sourceLight.getShadowGenerator();\n\n        effect.setTexture(\"shadowMapSampler\", generator.getShadowMap());\n        effect.setTexture(\"positionSampler\", geometry.textures[2]);\n        effect.setColor3(\"sunColor\", _this.sourceLight.diffuse);\n        effect.setVector3(\"sunDirection\", _this.sourceLight.getShadowDirection());\n        effect.setVector3(\"cameraPosition\", _this._scene.activeCamera.globalPosition);\n        effect.setMatrix(\"shadowViewProjection\", generator.getTransformMatrix());\n        effect.setFloat(\"scatteringCoefficient\", _this.volumetricLightCoefficient);\n        effect.setFloat(\"scatteringPower\", _this.volumetricLightPower);\n        depthValues.x = _this.sourceLight.getDepthMinZ(_this._scene.activeCamera);\n        depthValues.y = _this.sourceLight.getDepthMaxZ(_this._scene.activeCamera);\n        effect.setVector2(\"depthValues\", depthValues);\n      }\n    };\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLS\", function () {\n      return _this.volumetricLightPostProcess;\n    }, true)); // Smooth\n\n    this._createBlurPostProcesses(scene, ratio / 4, 0, \"volumetricLightBlurScale\"); // Merge\n\n\n    this.volumetricLightMergePostProces = new PostProcess(\"HDRVLSMerge\", \"standard\", [], [\"originalSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define VLSMERGE\");\n\n    this.volumetricLightMergePostProces.onApply = function (effect) {\n      effect.setTextureFromPostProcess(\"originalSampler\", _this._bloomEnabled ? _this.textureAdderFinalPostProcess : _this.originalPostProcess);\n      _this._currentDepthOfFieldSource = _this.volumetricLightFinalPostProcess;\n    };\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRVLSMerge\", function () {\n      return _this.volumetricLightMergePostProces;\n    }, true));\n  }; // Create luminance\n\n\n  StandardRenderingPipeline.prototype._createLuminancePostProcesses = function (scene, textureType) {\n    var _this = this; // Create luminance\n\n\n    var size = Math.pow(3, StandardRenderingPipeline.LuminanceSteps);\n    this.luminancePostProcess = new PostProcess(\"HDRLuminance\", \"standard\", [\"lumOffsets\"], [], {\n      width: size,\n      height: size\n    }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LUMINANCE\", textureType);\n    var offsets = [];\n\n    this.luminancePostProcess.onApply = function (effect) {\n      var sU = 1.0 / _this.luminancePostProcess.width;\n      var sV = 1.0 / _this.luminancePostProcess.height;\n      offsets[0] = -0.5 * sU;\n      offsets[1] = 0.5 * sV;\n      offsets[2] = 0.5 * sU;\n      offsets[3] = 0.5 * sV;\n      offsets[4] = -0.5 * sU;\n      offsets[5] = -0.5 * sV;\n      offsets[6] = 0.5 * sU;\n      offsets[7] = -0.5 * sV;\n      effect.setArray2(\"lumOffsets\", offsets);\n    }; // Add to pipeline\n\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLuminance\", function () {\n      return _this.luminancePostProcess;\n    }, true)); // Create down sample luminance\n\n    for (var i = StandardRenderingPipeline.LuminanceSteps - 1; i >= 0; i--) {\n      var size = Math.pow(3, i);\n      var defines = \"#define LUMINANCE_DOWN_SAMPLE\\n\";\n\n      if (i === 0) {\n        defines += \"#define FINAL_DOWN_SAMPLER\";\n      }\n\n      var postProcess = new PostProcess(\"HDRLuminanceDownSample\" + i, \"standard\", [\"dsOffsets\", \"halfDestPixelSize\"], [], {\n        width: size,\n        height: size\n      }, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines, textureType);\n      this.luminanceDownSamplePostProcesses.push(postProcess);\n    } // Create callbacks and add effects\n\n\n    var lastLuminance = this.luminancePostProcess;\n    this.luminanceDownSamplePostProcesses.forEach(function (pp, index) {\n      var downSampleOffsets = new Array(18);\n\n      pp.onApply = function (effect) {\n        if (!lastLuminance) {\n          return;\n        }\n\n        var id = 0;\n\n        for (var x = -1; x < 2; x++) {\n          for (var y = -1; y < 2; y++) {\n            downSampleOffsets[id] = x / lastLuminance.width;\n            downSampleOffsets[id + 1] = y / lastLuminance.height;\n            id += 2;\n          }\n        }\n\n        effect.setArray2(\"dsOffsets\", downSampleOffsets);\n        effect.setFloat(\"halfDestPixelSize\", 0.5 / lastLuminance.width);\n\n        if (index === _this.luminanceDownSamplePostProcesses.length - 1) {\n          lastLuminance = _this.luminancePostProcess;\n        } else {\n          lastLuminance = pp;\n        }\n      };\n\n      if (index === _this.luminanceDownSamplePostProcesses.length - 1) {\n        pp.onAfterRender = function () {\n          var pixel = scene.getEngine().readPixels(0, 0, 1, 1);\n          var bit_shift = new Vector4(1.0 / (255.0 * 255.0 * 255.0), 1.0 / (255.0 * 255.0), 1.0 / 255.0, 1.0);\n          _this._hdrCurrentLuminance = (pixel[0] * bit_shift.x + pixel[1] * bit_shift.y + pixel[2] * bit_shift.z + pixel[3] * bit_shift.w) / 100.0;\n        };\n      }\n\n      _this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLuminanceDownSample\" + index, function () {\n        return pp;\n      }, true));\n    });\n  }; // Create HDR post-process\n\n\n  StandardRenderingPipeline.prototype._createHdrPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    var defines = [\"#define HDR\"];\n\n    if (this._hdrAutoExposure) {\n      defines.push(\"#define AUTO_EXPOSURE\");\n    }\n\n    this.hdrPostProcess = new PostProcess(\"HDR\", \"standard\", [\"averageLuminance\"], [\"textureAdderSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, defines.join(\"\\n\"), 0);\n    var outputLiminance = 1;\n    var time = 0;\n    var lastTime = 0;\n\n    this.hdrPostProcess.onApply = function (effect) {\n      effect.setTextureFromPostProcess(\"textureAdderSampler\", _this._currentDepthOfFieldSource);\n      time += scene.getEngine().getDeltaTime();\n\n      if (outputLiminance < 0) {\n        outputLiminance = _this._hdrCurrentLuminance;\n      } else {\n        var dt = (lastTime - time) / 1000.0;\n\n        if (_this._hdrCurrentLuminance < outputLiminance + _this.hdrDecreaseRate * dt) {\n          outputLiminance += _this.hdrDecreaseRate * dt;\n        } else if (_this._hdrCurrentLuminance > outputLiminance - _this.hdrIncreaseRate * dt) {\n          outputLiminance -= _this.hdrIncreaseRate * dt;\n        } else {\n          outputLiminance = _this._hdrCurrentLuminance;\n        }\n      }\n\n      if (_this.hdrAutoExposure) {\n        _this._currentExposure = _this._fixedExposure / outputLiminance;\n      } else {\n        outputLiminance = Scalar.Clamp(outputLiminance, _this.hdrMinimumLuminance, 1e20);\n        effect.setFloat(\"averageLuminance\", outputLiminance);\n      }\n\n      lastTime = time;\n      _this._currentDepthOfFieldSource = _this.hdrFinalPostProcess;\n    };\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDR\", function () {\n      return _this.hdrPostProcess;\n    }, true));\n  }; // Create lens flare post-process\n\n\n  StandardRenderingPipeline.prototype._createLensFlarePostProcess = function (scene, ratio) {\n    var _this = this;\n\n    this.lensFlarePostProcess = new PostProcess(\"HDRLensFlare\", \"standard\", [\"strength\", \"ghostDispersal\", \"haloWidth\", \"resolution\", \"distortionStrength\"], [\"lensColorSampler\"], ratio / 2, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LENS_FLARE\", 0);\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLensFlare\", function () {\n      return _this.lensFlarePostProcess;\n    }, true));\n\n    this._createBlurPostProcesses(scene, ratio / 4, 2, \"lensFlareBlurWidth\");\n\n    this.lensFlareComposePostProcess = new PostProcess(\"HDRLensFlareCompose\", \"standard\", [\"lensStarMatrix\"], [\"otherSampler\", \"lensDirtSampler\", \"lensStarSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define LENS_FLARE_COMPOSE\", 0);\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRLensFlareCompose\", function () {\n      return _this.lensFlareComposePostProcess;\n    }, true));\n    var resolution = new Vector2(0, 0); // Lens flare\n\n    this.lensFlarePostProcess.onApply = function (effect) {\n      effect.setTextureFromPostProcess(\"textureSampler\", _this._bloomEnabled ? _this.blurHPostProcesses[0] : _this.originalPostProcess);\n      effect.setTexture(\"lensColorSampler\", _this.lensColorTexture);\n      effect.setFloat(\"strength\", _this.lensFlareStrength);\n      effect.setFloat(\"ghostDispersal\", _this.lensFlareGhostDispersal);\n      effect.setFloat(\"haloWidth\", _this.lensFlareHaloWidth); // Shift\n\n      resolution.x = _this.lensFlarePostProcess.width;\n      resolution.y = _this.lensFlarePostProcess.height;\n      effect.setVector2(\"resolution\", resolution);\n      effect.setFloat(\"distortionStrength\", _this.lensFlareDistortionStrength);\n    }; // Compose\n\n\n    var scaleBias1 = Matrix.FromValues(2.0, 0.0, -1.0, 0.0, 0.0, 2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n    var scaleBias2 = Matrix.FromValues(0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n\n    this.lensFlareComposePostProcess.onApply = function (effect) {\n      if (!_this._scene.activeCamera) {\n        return;\n      }\n\n      effect.setTextureFromPostProcess(\"otherSampler\", _this.lensFlarePostProcess);\n      effect.setTexture(\"lensDirtSampler\", _this.lensFlareDirtTexture);\n      effect.setTexture(\"lensStarSampler\", _this.lensStarTexture); // Lens start rotation matrix\n\n      var camerax = _this._scene.activeCamera.getViewMatrix().getRow(0);\n\n      var cameraz = _this._scene.activeCamera.getViewMatrix().getRow(2);\n\n      var camRot = Vector3.Dot(camerax.toVector3(), new Vector3(1.0, 0.0, 0.0)) + Vector3.Dot(cameraz.toVector3(), new Vector3(0.0, 0.0, 1.0));\n      camRot *= 4.0;\n      var starRotation = Matrix.FromValues(Math.cos(camRot) * 0.5, -Math.sin(camRot), 0.0, 0.0, Math.sin(camRot), Math.cos(camRot) * 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0);\n      var lensStarMatrix = scaleBias2.multiply(starRotation).multiply(scaleBias1);\n      effect.setMatrix(\"lensStarMatrix\", lensStarMatrix);\n      _this._currentDepthOfFieldSource = _this.lensFlareFinalPostProcess;\n    };\n  }; // Create depth-of-field post-process\n\n\n  StandardRenderingPipeline.prototype._createDepthOfFieldPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    this.depthOfFieldPostProcess = new PostProcess(\"HDRDepthOfField\", \"standard\", [\"distance\"], [\"otherSampler\", \"depthSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define DEPTH_OF_FIELD\", 0);\n\n    this.depthOfFieldPostProcess.onApply = function (effect) {\n      effect.setTextureFromPostProcess(\"otherSampler\", _this._currentDepthOfFieldSource);\n      effect.setTexture(\"depthSampler\", _this._getDepthTexture());\n      effect.setFloat(\"distance\", _this.depthOfFieldDistance);\n    }; // Add to pipeline\n\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRDepthOfField\", function () {\n      return _this.depthOfFieldPostProcess;\n    }, true));\n  }; // Create motion blur post-process\n\n\n  StandardRenderingPipeline.prototype._createMotionBlurPostProcess = function (scene, ratio) {\n    var _this = this;\n\n    if (this._isObjectBasedMotionBlur) {\n      var mb = new MotionBlurPostProcess(\"HDRMotionBlur\", scene, ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, 0);\n      mb.motionStrength = this.motionStrength;\n      mb.motionBlurSamples = this.motionBlurSamples;\n      this.motionBlurPostProcess = mb;\n    } else {\n      this.motionBlurPostProcess = new PostProcess(\"HDRMotionBlur\", \"standard\", [\"inverseViewProjection\", \"prevViewProjection\", \"screenSize\", \"motionScale\", \"motionStrength\"], [\"depthSampler\"], ratio, null, Texture.BILINEAR_SAMPLINGMODE, scene.getEngine(), false, \"#define MOTION_BLUR\\n#define MAX_MOTION_SAMPLES \" + this.motionBlurSamples.toFixed(1), 0);\n      var motionScale = 0;\n      var prevViewProjection = Matrix.Identity();\n      var invViewProjection = Matrix.Identity();\n      var viewProjection = Matrix.Identity();\n      var screenSize = Vector2.Zero();\n\n      this.motionBlurPostProcess.onApply = function (effect) {\n        viewProjection = scene.getProjectionMatrix().multiply(scene.getViewMatrix());\n        viewProjection.invertToRef(invViewProjection);\n        effect.setMatrix(\"inverseViewProjection\", invViewProjection);\n        effect.setMatrix(\"prevViewProjection\", prevViewProjection);\n        prevViewProjection = viewProjection;\n        screenSize.x = _this.motionBlurPostProcess.width;\n        screenSize.y = _this.motionBlurPostProcess.height;\n        effect.setVector2(\"screenSize\", screenSize);\n        motionScale = scene.getEngine().getFps() / 60.0;\n        effect.setFloat(\"motionScale\", motionScale);\n        effect.setFloat(\"motionStrength\", _this.motionStrength);\n        effect.setTexture(\"depthSampler\", _this._getDepthTexture());\n      };\n    }\n\n    this.addEffect(new PostProcessRenderEffect(scene.getEngine(), \"HDRMotionBlur\", function () {\n      return _this.motionBlurPostProcess;\n    }, true));\n  };\n\n  StandardRenderingPipeline.prototype._getDepthTexture = function () {\n    if (this._scene.getEngine().getCaps().drawBuffersExtension) {\n      var renderer = this._scene.enableGeometryBufferRenderer();\n\n      return renderer.getGBuffer().textures[0];\n    }\n\n    return this._scene.enableDepthRenderer().getDepthMap();\n  };\n\n  StandardRenderingPipeline.prototype._disposePostProcesses = function () {\n    for (var i = 0; i < this._cameras.length; i++) {\n      var camera = this._cameras[i];\n\n      if (this.originalPostProcess) {\n        this.originalPostProcess.dispose(camera);\n      }\n\n      if (this.screenSpaceReflectionPostProcess) {\n        this.screenSpaceReflectionPostProcess.dispose(camera);\n      }\n\n      if (this.downSampleX4PostProcess) {\n        this.downSampleX4PostProcess.dispose(camera);\n      }\n\n      if (this.brightPassPostProcess) {\n        this.brightPassPostProcess.dispose(camera);\n      }\n\n      if (this.textureAdderPostProcess) {\n        this.textureAdderPostProcess.dispose(camera);\n      }\n\n      if (this.volumetricLightPostProcess) {\n        this.volumetricLightPostProcess.dispose(camera);\n      }\n\n      if (this.volumetricLightSmoothXPostProcess) {\n        this.volumetricLightSmoothXPostProcess.dispose(camera);\n      }\n\n      if (this.volumetricLightSmoothYPostProcess) {\n        this.volumetricLightSmoothYPostProcess.dispose(camera);\n      }\n\n      if (this.volumetricLightMergePostProces) {\n        this.volumetricLightMergePostProces.dispose(camera);\n      }\n\n      if (this.volumetricLightFinalPostProcess) {\n        this.volumetricLightFinalPostProcess.dispose(camera);\n      }\n\n      if (this.lensFlarePostProcess) {\n        this.lensFlarePostProcess.dispose(camera);\n      }\n\n      if (this.lensFlareComposePostProcess) {\n        this.lensFlareComposePostProcess.dispose(camera);\n      }\n\n      for (var j = 0; j < this.luminanceDownSamplePostProcesses.length; j++) {\n        this.luminanceDownSamplePostProcesses[j].dispose(camera);\n      }\n\n      if (this.luminancePostProcess) {\n        this.luminancePostProcess.dispose(camera);\n      }\n\n      if (this.hdrPostProcess) {\n        this.hdrPostProcess.dispose(camera);\n      }\n\n      if (this.hdrFinalPostProcess) {\n        this.hdrFinalPostProcess.dispose(camera);\n      }\n\n      if (this.depthOfFieldPostProcess) {\n        this.depthOfFieldPostProcess.dispose(camera);\n      }\n\n      if (this.motionBlurPostProcess) {\n        this.motionBlurPostProcess.dispose(camera);\n      }\n\n      if (this.fxaaPostProcess) {\n        this.fxaaPostProcess.dispose(camera);\n      }\n\n      for (var j = 0; j < this.blurHPostProcesses.length; j++) {\n        this.blurHPostProcesses[j].dispose(camera);\n      }\n\n      for (var j = 0; j < this.blurVPostProcesses.length; j++) {\n        this.blurVPostProcesses[j].dispose(camera);\n      }\n    }\n\n    this.originalPostProcess = null;\n    this.downSampleX4PostProcess = null;\n    this.brightPassPostProcess = null;\n    this.textureAdderPostProcess = null;\n    this.textureAdderFinalPostProcess = null;\n    this.volumetricLightPostProcess = null;\n    this.volumetricLightSmoothXPostProcess = null;\n    this.volumetricLightSmoothYPostProcess = null;\n    this.volumetricLightMergePostProces = null;\n    this.volumetricLightFinalPostProcess = null;\n    this.lensFlarePostProcess = null;\n    this.lensFlareComposePostProcess = null;\n    this.luminancePostProcess = null;\n    this.hdrPostProcess = null;\n    this.hdrFinalPostProcess = null;\n    this.depthOfFieldPostProcess = null;\n    this.motionBlurPostProcess = null;\n    this.fxaaPostProcess = null;\n    this.screenSpaceReflectionPostProcess = null;\n    this.luminanceDownSamplePostProcesses = [];\n    this.blurHPostProcesses = [];\n    this.blurVPostProcesses = [];\n  };\n  /**\r\n   * Dispose of the pipeline and stop all post processes\r\n   */\n\n\n  StandardRenderingPipeline.prototype.dispose = function () {\n    this._disposePostProcesses();\n\n    this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n\n    _super.prototype.dispose.call(this);\n  };\n  /**\r\n   * Serialize the rendering pipeline (Used when exporting)\r\n   * @returns the serialized object\r\n   */\n\n\n  StandardRenderingPipeline.prototype.serialize = function () {\n    var serializationObject = SerializationHelper.Serialize(this);\n\n    if (this.sourceLight) {\n      serializationObject.sourceLightId = this.sourceLight.id;\n    }\n\n    if (this.screenSpaceReflectionPostProcess) {\n      serializationObject.screenSpaceReflectionPostProcess = SerializationHelper.Serialize(this.screenSpaceReflectionPostProcess);\n    }\n\n    serializationObject.customType = \"StandardRenderingPipeline\";\n    return serializationObject;\n  };\n  /**\r\n   * Parse the serialized pipeline\r\n   * @param source Source pipeline.\r\n   * @param scene The scene to load the pipeline to.\r\n   * @param rootUrl The URL of the serialized pipeline.\r\n   * @returns An instantiated pipeline from the serialized object.\r\n   */\n\n\n  StandardRenderingPipeline.Parse = function (source, scene, rootUrl) {\n    var p = SerializationHelper.Parse(function () {\n      return new StandardRenderingPipeline(source._name, scene, source._ratio);\n    }, source, scene, rootUrl);\n\n    if (source.sourceLightId) {\n      p.sourceLight = scene.getLightByID(source.sourceLightId);\n    }\n\n    if (source.screenSpaceReflectionPostProcess) {\n      SerializationHelper.Parse(function () {\n        return p.screenSpaceReflectionPostProcess;\n      }, source.screenSpaceReflectionPostProcess, scene, rootUrl);\n    }\n\n    return p;\n  };\n  /**\r\n   * Luminance steps\r\n   */\n\n\n  StandardRenderingPipeline.LuminanceSteps = 6;\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"brightThreshold\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"blurWidth\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"horizontalBlur\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"exposure\", null);\n\n  __decorate([serializeAsTexture(\"lensTexture\")], StandardRenderingPipeline.prototype, \"lensTexture\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightCoefficient\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightPower\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightBlurScale\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrMinimumLuminance\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrDecreaseRate\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrIncreaseRate\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"hdrAutoExposure\", null);\n\n  __decorate([serializeAsTexture(\"lensColorTexture\")], StandardRenderingPipeline.prototype, \"lensColorTexture\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareStrength\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareGhostDispersal\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareHaloWidth\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareDistortionStrength\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"lensFlareBlurWidth\", void 0);\n\n  __decorate([serializeAsTexture(\"lensStarTexture\")], StandardRenderingPipeline.prototype, \"lensStarTexture\", void 0);\n\n  __decorate([serializeAsTexture(\"lensFlareDirtTexture\")], StandardRenderingPipeline.prototype, \"lensFlareDirtTexture\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"depthOfFieldDistance\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"depthOfFieldBlurWidth\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"motionStrength\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"objectBasedMotionBlur\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"_ratio\", void 0);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"BloomEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"DepthOfFieldEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"LensFlareEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"HDREnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"VLSEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"MotionBlurEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"fxaaEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"screenSpaceReflectionsEnabled\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"volumetricLightStepsCount\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"motionBlurSamples\", null);\n\n  __decorate([serialize()], StandardRenderingPipeline.prototype, \"samples\", null);\n\n  return StandardRenderingPipeline;\n}(PostProcessRenderPipeline);\n\nexport { StandardRenderingPipeline };\n_TypeStore.RegisteredTypes[\"BABYLON.StandardRenderingPipeline\"] = StandardRenderingPipeline;","map":null,"metadata":{},"sourceType":"module"}