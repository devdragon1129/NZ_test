{"ast":null,"code":"import _regeneratorRuntime from \"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _slicedToArray from \"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _objectSpread from \"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/objectSpread\";\nimport _toConsumableArray from \"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _asyncToGenerator from \"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport { Locale, WearableCategory } from '@dcl/schemas';\nimport { EntityType } from 'dcl-catalyst-commons';\nimport { calculateMultipleHashesADR32, calculateMultipleHashesADR32LegacyQmHash } from '@dcl/hashing';\nimport { buildCatalystItemURN } from 'lib/urn';\nimport { makeContentFiles, computeHashes } from 'modules/deployment/contentUtils';\nimport { IMAGE_PATH, THUMBNAIL_PATH, ItemType, EmoteCategory, EntityHashingType } from './types';\nimport { generateCatalystImage, generateImage } from './utils';\n/**\n * Checks if a hash was generated using an older algorithm.\n *\n * @param hash - A hash.\n * @returns true if the hash is from an older version.\n */\n\nexport function isOldHash(hash) {\n  return hash.startsWith('Qm');\n}\n/**\n * Checks if an item has content hashes generated using an older algorithm.\n *\n * @param item - An item.\n * @returns true if the item has older hashes.\n */\n\nexport function hasOldHashedContents(item) {\n  return Object.values(item.contents).some(function (hash) {\n    return isOldHash(hash);\n  });\n}\n/**\n * Takes a map of contents (file name -> hash), downloads the contents that are hashed with an older algorithm\n * and builds a new map that contains the content and their hash.\n *\n * @param contents - The contents to be updated.\n * @returns A map containing only the contents that have been updated and re-hashed.\n */\n\nexport function reHashOlderContents(_x, _x2) {\n  return _reHashOlderContents.apply(this, arguments);\n}\n/**\n * Gets an array of unique files based on their hashes.\n *\n * @param hashes - The record of names->hashes.\n * @param blobs - The record of names->blobs.\n */\n\nfunction _reHashOlderContents() {\n  _reHashOlderContents = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(contents, legacyBuilderClient) {\n    var contentsWithOldHashes, contentOfOldHashedFiles, newHashesOfOldHashedFiles;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            contentsWithOldHashes = Object.fromEntries(Object.entries(contents).filter(function (_ref) {\n              var _ref2 = _slicedToArray(_ref, 2),\n                  _ = _ref2[0],\n                  content = _ref2[1];\n\n              return isOldHash(content);\n            }));\n            _context.next = 3;\n            return legacyBuilderClient.fetchContents(contentsWithOldHashes);\n\n          case 3:\n            contentOfOldHashedFiles = _context.sent;\n            _context.next = 6;\n            return computeHashes(contentOfOldHashedFiles);\n\n          case 6:\n            newHashesOfOldHashedFiles = _context.sent;\n            return _context.abrupt(\"return\", Object.fromEntries(Object.keys(contentsWithOldHashes).map(function (key) {\n              return [key, {\n                hash: newHashesOfOldHashedFiles[key],\n                content: contentOfOldHashedFiles[key]\n              }];\n            })));\n\n          case 8:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n  return _reHashOlderContents.apply(this, arguments);\n}\n\nfunction getUniqueFiles(hashes, blobs) {\n  var uniqueFileHashes = _toConsumableArray(new Set(Object.values(hashes)));\n\n  var inverseFileHashesRecord = Object.keys(hashes).reduce(function (obj, key) {\n    obj[hashes[key]] = key;\n    return obj;\n  }, {});\n  return uniqueFileHashes.map(function (hash) {\n    return blobs[inverseFileHashesRecord[hash]];\n  });\n}\n/**\n * Calculates the final size (with the already stored content and the new one) of the contents of an item.\n * All the files in newContents must also be in the item's contents in both name and hash.\n *\n * @param item - An item that contains the old and the new hashed content.\n * @param newContents - The new content that is going to be added to the item.\n */\n\n\nexport function calculateFinalSize(_x3, _x4, _x5) {\n  return _calculateFinalSize.apply(this, arguments);\n}\n/**\n * Sums the sizes of an array of blobs.\n *\n * @param files - An array of blobs.\n */\n\nfunction _calculateFinalSize() {\n  _calculateFinalSize = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(item, newContents, legacyBuilderClient) {\n    var newHashes, filesToDownload, fileName, blobs, allBlobs, allHashes, imageSize, image, uniqueFiles;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return computeHashes(newContents);\n\n          case 2:\n            newHashes = _context2.sent;\n            filesToDownload = {};\n\n            for (fileName in item.contents) {\n              if (!newHashes[fileName] || item.contents[fileName] !== newHashes[fileName]) {\n                filesToDownload[fileName] = item.contents[fileName];\n              }\n            }\n\n            _context2.next = 7;\n            return legacyBuilderClient.fetchContents(filesToDownload);\n\n          case 7:\n            blobs = _context2.sent;\n            allBlobs = _objectSpread({}, newContents, blobs);\n            allHashes = _objectSpread({}, newHashes, filesToDownload);\n            imageSize = 0; // Only generate the catalyst image if there isn't one already\n\n            if (allBlobs[IMAGE_PATH]) {\n              _context2.next = 21;\n              break;\n            }\n\n            _context2.prev = 12;\n            _context2.next = 15;\n            return generateImage(item, {\n              thumbnail: allBlobs[THUMBNAIL_PATH]\n            });\n\n          case 15:\n            image = _context2.sent;\n            imageSize = image.size;\n            _context2.next = 21;\n            break;\n\n          case 19:\n            _context2.prev = 19;\n            _context2.t0 = _context2[\"catch\"](12);\n\n          case 21:\n            uniqueFiles = getUniqueFiles(allHashes, allBlobs);\n            return _context2.abrupt(\"return\", imageSize + calculateFilesSize(uniqueFiles));\n\n          case 23:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2, null, [[12, 19]]);\n  }));\n  return _calculateFinalSize.apply(this, arguments);\n}\n\nfunction calculateFilesSize(files) {\n  return files.reduce(function (total, blob) {\n    return blob.size + total;\n  }, 0);\n}\n\nfunction getMerkleProof(tree, entityHash, entityValues) {\n  var hashingKeys = Object.keys(entityValues);\n  var _tree$proofs$entityHa = tree.proofs[entityHash],\n      index = _tree$proofs$entityHa.index,\n      proof = _tree$proofs$entityHa.proof;\n  return {\n    index: index,\n    proof: proof,\n    hashingKeys: hashingKeys,\n    entityHash: entityHash\n  };\n}\n\nfunction buildTPItemEntityMetadata(item, itemHash, tree) {\n  if (!item.urn) {\n    throw new Error('Item does not have URN');\n  } // The order of the metadata properties can't be changed. Changing it will result in a different content hash.\n\n\n  var baseEntityData = {\n    id: item.urn,\n    name: item.name,\n    description: item.description,\n    i18n: [{\n      code: Locale.EN,\n      text: item.name\n    }],\n    data: {\n      replaces: item.data.replaces,\n      hides: item.data.hides,\n      tags: item.data.tags,\n      category: item.data.category,\n      representations: item.data.representations\n    },\n    image: IMAGE_PATH,\n    thumbnail: THUMBNAIL_PATH,\n    metrics: item.metrics,\n    content: item.contents\n  };\n  return _objectSpread({}, baseEntityData, {\n    merkleProof: getMerkleProof(tree, itemHash, baseEntityData)\n  });\n}\n\nfunction buildItemEntityMetadata(collection, item) {\n  if (!collection.contractAddress || !item.tokenId) {\n    throw new Error('You need the collection and item to be published');\n  } // The order of the metadata properties can't be changed. Changing it will result in a different content hash.\n\n\n  var catalystItem = {\n    id: buildCatalystItemURN(collection.contractAddress, item.tokenId),\n    name: item.name,\n    description: item.description,\n    collectionAddress: collection.contractAddress,\n    rarity: item.rarity,\n    i18n: [{\n      code: Locale.EN,\n      text: item.name\n    }],\n    data: {\n      replaces: item.data.replaces,\n      hides: item.data.hides,\n      tags: item.data.tags,\n      category: item.data.category,\n      representations: item.data.representations\n    },\n    image: IMAGE_PATH,\n    thumbnail: THUMBNAIL_PATH,\n    metrics: item.metrics\n  };\n\n  if (item.type === ItemType.EMOTE) {\n    catalystItem.emoteDataV0 = {\n      loop: item.data.category === EmoteCategory.LOOP\n    }; // add missing properties from wearable schema so catalyst wont reject the deployment\n\n    catalystItem.data.category = WearableCategory.HAT;\n    catalystItem.data.hides = [];\n    catalystItem.data.replaces = [];\n    catalystItem.data.representations = catalystItem.data.representations.map(function (representation) {\n      return _objectSpread({}, representation, {\n        overrideHides: [],\n        overrideReplaces: []\n      });\n    });\n  }\n\n  return catalystItem;\n}\n\nfunction buildItemEntityContent(_x6) {\n  return _buildItemEntityContent.apply(this, arguments);\n}\n\nfunction _buildItemEntityContent() {\n  _buildItemEntityContent = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(item) {\n    var contents, catalystItem;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            contents = _objectSpread({}, item.contents);\n\n            if (item.contents[IMAGE_PATH]) {\n              _context3.next = 6;\n              break;\n            }\n\n            _context3.next = 4;\n            return generateCatalystImage(item);\n\n          case 4:\n            catalystItem = _context3.sent;\n            contents[IMAGE_PATH] = catalystItem.hash;\n\n          case 6:\n            return _context3.abrupt(\"return\", contents);\n\n          case 7:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n  return _buildItemEntityContent.apply(this, arguments);\n}\n\nfunction buildItemEntityBlobs(_x7, _x8) {\n  return _buildItemEntityBlobs.apply(this, arguments);\n}\n\nfunction _buildItemEntityBlobs() {\n  _buildItemEntityBlobs = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(item, legacyBuilderClient) {\n    var _yield$Promise$all, _yield$Promise$all2, files, image;\n\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return Promise.all([legacyBuilderClient.fetchContents(item.contents), !item.contents[IMAGE_PATH] ? generateImage(item) : null]);\n\n          case 2:\n            _yield$Promise$all = _context4.sent;\n            _yield$Promise$all2 = _slicedToArray(_yield$Promise$all, 2);\n            files = _yield$Promise$all2[0];\n            image = _yield$Promise$all2[1];\n            files[IMAGE_PATH] = image !== null && image !== void 0 ? image : files[IMAGE_PATH];\n            return _context4.abrupt(\"return\", files);\n\n          case 8:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n  return _buildItemEntityBlobs.apply(this, arguments);\n}\n\nexport function buildItemEntity(_x9, _x10, _x11, _x12, _x13, _x14) {\n  return _buildItemEntity.apply(this, arguments);\n}\n\nfunction _buildItemEntity() {\n  _buildItemEntity = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(client, legacyBuilderClient, collection, item, tree, itemHash) {\n    var blobs, files, metadata;\n    return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n      while (1) {\n        switch (_context5.prev = _context5.next) {\n          case 0:\n            _context5.next = 2;\n            return buildItemEntityBlobs(item, legacyBuilderClient);\n\n          case 2:\n            blobs = _context5.sent;\n            _context5.next = 5;\n            return makeContentFiles(blobs);\n\n          case 5:\n            files = _context5.sent;\n            metadata = tree && itemHash ? buildTPItemEntityMetadata(item, itemHash, tree) : buildItemEntityMetadata(collection, item);\n            return _context5.abrupt(\"return\", client.buildEntity({\n              type: EntityType.WEARABLE,\n              pointers: [metadata.id],\n              metadata: metadata,\n              files: files,\n              timestamp: Date.now()\n            }));\n\n          case 8:\n          case \"end\":\n            return _context5.stop();\n        }\n      }\n    }, _callee5);\n  }));\n  return _buildItemEntity.apply(this, arguments);\n}\n\nexport function buildStandardItemEntity(_x15, _x16, _x17, _x18) {\n  return _buildStandardItemEntity.apply(this, arguments);\n}\n\nfunction _buildStandardItemEntity() {\n  _buildStandardItemEntity = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6(client, legacyBuilderClient, collection, item) {\n    return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            return _context6.abrupt(\"return\", buildItemEntity(client, legacyBuilderClient, collection, item));\n\n          case 1:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee6);\n  }));\n  return _buildStandardItemEntity.apply(this, arguments);\n}\n\nexport function buildTPItemEntity(_x19, _x20, _x21, _x22, _x23, _x24) {\n  return _buildTPItemEntity.apply(this, arguments);\n}\n\nfunction _buildTPItemEntity() {\n  _buildTPItemEntity = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee7(client, legacyBuilderClient, collection, item, tree, itemHash) {\n    return _regeneratorRuntime.wrap(function _callee7$(_context7) {\n      while (1) {\n        switch (_context7.prev = _context7.next) {\n          case 0:\n            return _context7.abrupt(\"return\", buildItemEntity(client, legacyBuilderClient, collection, item, tree, itemHash));\n\n          case 1:\n          case \"end\":\n            return _context7.stop();\n        }\n      }\n    }, _callee7);\n  }));\n  return _buildTPItemEntity.apply(this, arguments);\n}\n\nexport function buildStandardWearableContentHash(_x25, _x26) {\n  return _buildStandardWearableContentHash.apply(this, arguments);\n}\n\nfunction _buildStandardWearableContentHash() {\n  _buildStandardWearableContentHash = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee8(collection, item) {\n    var hashingType,\n        hashes,\n        content,\n        metadata,\n        _args8 = arguments;\n    return _regeneratorRuntime.wrap(function _callee8$(_context8) {\n      while (1) {\n        switch (_context8.prev = _context8.next) {\n          case 0:\n            hashingType = _args8.length > 2 && _args8[2] !== undefined ? _args8[2] : EntityHashingType.V1;\n            _context8.next = 3;\n            return buildItemEntityContent(item);\n\n          case 3:\n            hashes = _context8.sent;\n            content = Object.keys(hashes).map(function (file) {\n              return {\n                file: file,\n                hash: hashes[file]\n              };\n            });\n            metadata = buildItemEntityMetadata(collection, item);\n\n            if (!(hashingType === EntityHashingType.V0)) {\n              _context8.next = 12;\n              break;\n            }\n\n            _context8.next = 9;\n            return calculateMultipleHashesADR32LegacyQmHash(content, metadata);\n\n          case 9:\n            return _context8.abrupt(\"return\", _context8.sent.hash);\n\n          case 12:\n            _context8.next = 14;\n            return calculateMultipleHashesADR32(content, metadata);\n\n          case 14:\n            return _context8.abrupt(\"return\", _context8.sent.hash);\n\n          case 15:\n          case \"end\":\n            return _context8.stop();\n        }\n      }\n    }, _callee8);\n  }));\n  return _buildStandardWearableContentHash.apply(this, arguments);\n}","map":{"version":3,"sources":["/opt/work/NZ_test/src/modules/item/export.ts"],"names":["Locale","WearableCategory","EntityType","calculateMultipleHashesADR32","calculateMultipleHashesADR32LegacyQmHash","buildCatalystItemURN","makeContentFiles","computeHashes","IMAGE_PATH","THUMBNAIL_PATH","ItemType","EmoteCategory","EntityHashingType","generateCatalystImage","generateImage","isOldHash","hash","startsWith","hasOldHashedContents","item","Object","values","contents","some","reHashOlderContents","legacyBuilderClient","contentsWithOldHashes","fromEntries","entries","filter","_","content","fetchContents","contentOfOldHashedFiles","newHashesOfOldHashedFiles","keys","map","key","getUniqueFiles","hashes","blobs","uniqueFileHashes","Set","inverseFileHashesRecord","reduce","obj","calculateFinalSize","newContents","newHashes","filesToDownload","fileName","allBlobs","allHashes","imageSize","thumbnail","image","size","uniqueFiles","calculateFilesSize","files","total","blob","getMerkleProof","tree","entityHash","entityValues","hashingKeys","proofs","index","proof","buildTPItemEntityMetadata","itemHash","urn","Error","baseEntityData","id","name","description","i18n","code","EN","text","data","replaces","hides","tags","category","representations","metrics","merkleProof","buildItemEntityMetadata","collection","contractAddress","tokenId","catalystItem","collectionAddress","rarity","type","EMOTE","emoteDataV0","loop","LOOP","HAT","representation","overrideHides","overrideReplaces","buildItemEntityContent","buildItemEntityBlobs","Promise","all","buildItemEntity","client","metadata","buildEntity","WEARABLE","pointers","timestamp","Date","now","buildStandardItemEntity","buildTPItemEntity","buildStandardWearableContentHash","hashingType","V1","file","V0"],"mappings":";;;;;AAAA,SAASA,MAAT,EAA6CC,gBAA7C,QAA6F,cAA7F;AAGA,SAASC,UAAT,QAA2B,sBAA3B;AACA,SAASC,4BAAT,EAAuCC,wCAAvC,QAAuF,cAAvF;AAEA,SAASC,oBAAT,QAAqC,SAArC;AACA,SAASC,gBAAT,EAA2BC,aAA3B,QAAgD,iCAAhD;AAEA,SAAeC,UAAf,EAA2BC,cAA3B,EAAiEC,QAAjE,EAAsFC,aAAtF,EAAqGC,iBAArG,QAA8H,SAA9H;AACA,SAASC,qBAAT,EAAgCC,aAAhC,QAAqD,SAArD;AAEA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,SAAT,CAAmBC,IAAnB,EAA0C;AAC/C,SAAOA,IAAI,CAACC,UAAL,CAAgB,IAAhB,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,oBAAT,CAA8BC,IAA9B,EAAmD;AACxD,SAAOC,MAAM,CAACC,MAAP,CAAcF,IAAI,CAACG,QAAnB,EAA6BC,IAA7B,CAAkC,UAAAP,IAAI;AAAA,WAAID,SAAS,CAACC,IAAD,CAAb;AAAA,GAAtC,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,gBAAsBQ,mBAAtB;AAAA;AAAA;AAYA;AACA;AACA;AACA;AACA;AACA;;;kFAjBO,iBACLF,QADK,EAELG,mBAFK;AAAA;AAAA;AAAA;AAAA;AAAA;AAICC,YAAAA,qBAJD,GAIyBN,MAAM,CAACO,WAAP,CAAmBP,MAAM,CAACQ,OAAP,CAAeN,QAAf,EAAyBO,MAAzB,CAAgC;AAAA;AAAA,kBAAEC,CAAF;AAAA,kBAAKC,OAAL;;AAAA,qBAAkBhB,SAAS,CAACgB,OAAD,CAA3B;AAAA,aAAhC,CAAnB,CAJzB;AAAA;AAAA,mBAKiCN,mBAAmB,CAACO,aAApB,CAAkCN,qBAAlC,CALjC;;AAAA;AAKCO,YAAAA,uBALD;AAAA;AAAA,mBAMmC1B,aAAa,CAAC0B,uBAAD,CANhD;;AAAA;AAMCC,YAAAA,yBAND;AAAA,6CAOEd,MAAM,CAACO,WAAP,CACLP,MAAM,CAACe,IAAP,CAAYT,qBAAZ,EAAmCU,GAAnC,CAAuC,UAAAC,GAAG;AAAA,qBAAI,CAACA,GAAD,EAAM;AAAErB,gBAAAA,IAAI,EAAEkB,yBAAyB,CAACG,GAAD,CAAjC;AAAwCN,gBAAAA,OAAO,EAAEE,uBAAuB,CAACI,GAAD;AAAxE,eAAN,CAAJ;AAAA,aAA1C,CADK,CAPF;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAkBP,SAASC,cAAT,CAAwBC,MAAxB,EAAwDC,KAAxD,EAAkG;AAChG,MAAMC,gBAA+B,sBAAO,IAAIC,GAAJ,CAAQtB,MAAM,CAACC,MAAP,CAAckB,MAAd,CAAR,CAAP,CAArC;;AACA,MAAMI,uBAAuB,GAAGvB,MAAM,CAACe,IAAP,CAAYI,MAAZ,EAAoBK,MAApB,CAA2B,UAACC,GAAD,EAA8BR,GAA9B,EAA8C;AACvGQ,IAAAA,GAAG,CAACN,MAAM,CAACF,GAAD,CAAP,CAAH,GAAmBA,GAAnB;AACA,WAAOQ,GAAP;AACD,GAH+B,EAG7B,EAH6B,CAAhC;AAIA,SAAOJ,gBAAgB,CAACL,GAAjB,CAAqB,UAAApB,IAAI;AAAA,WAAIwB,KAAK,CAACG,uBAAuB,CAAC3B,IAAD,CAAxB,CAAT;AAAA,GAAzB,CAAP;AACD;AAED;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,gBAAsB8B,kBAAtB;AAAA;AAAA;AA0BA;AACA;AACA;AACA;AACA;;;iFA9BO,kBAAkC3B,IAAlC,EAA8C4B,WAA9C,EAAiFtB,mBAAjF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACmBlB,aAAa,CAACwC,WAAD,CADhC;;AAAA;AACCC,YAAAA,SADD;AAECC,YAAAA,eAFD,GAE2C,EAF3C;;AAGL,iBAAWC,QAAX,IAAuB/B,IAAI,CAACG,QAA5B,EAAsC;AACpC,kBAAI,CAAC0B,SAAS,CAACE,QAAD,CAAV,IAAwB/B,IAAI,CAACG,QAAL,CAAc4B,QAAd,MAA4BF,SAAS,CAACE,QAAD,CAAjE,EAA6E;AAC3ED,gBAAAA,eAAe,CAACC,QAAD,CAAf,GAA4B/B,IAAI,CAACG,QAAL,CAAc4B,QAAd,CAA5B;AACD;AACF;;AAPI;AAAA,mBASezB,mBAAmB,CAACO,aAApB,CAAkCiB,eAAlC,CATf;;AAAA;AASCT,YAAAA,KATD;AAUCW,YAAAA,QAVD,qBAUiBJ,WAVjB,EAUiCP,KAVjC;AAWCY,YAAAA,SAXD,qBAWkBJ,SAXlB,EAWgCC,eAXhC;AAaDI,YAAAA,SAbC,GAaW,CAbX,EAcL;;AAdK,gBAeAF,QAAQ,CAAC3C,UAAD,CAfR;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,mBAiBmBM,aAAa,CAACK,IAAD,EAAO;AAAEmC,cAAAA,SAAS,EAAEH,QAAQ,CAAC1C,cAAD;AAArB,aAAP,CAjBhC;;AAAA;AAiBK8C,YAAAA,KAjBL;AAkBDF,YAAAA,SAAS,GAAGE,KAAK,CAACC,IAAlB;AAlBC;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAsBCC,YAAAA,WAtBD,GAsBenB,cAAc,CAACc,SAAD,EAAYD,QAAZ,CAtB7B;AAAA,8CAuBEE,SAAS,GAAGK,kBAAkB,CAACD,WAAD,CAvBhC;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AA+BP,SAASC,kBAAT,CAA4BC,KAA5B,EAAgD;AAC9C,SAAOA,KAAK,CAACf,MAAN,CAAa,UAACgB,KAAD,EAAQC,IAAR;AAAA,WAAiBA,IAAI,CAACL,IAAL,GAAYI,KAA7B;AAAA,GAAb,EAAiD,CAAjD,CAAP;AACD;;AAED,SAASE,cAAT,CAAwBC,IAAxB,EAAqDC,UAArD,EAAyEC,YAAzE,EAAgI;AAC9H,MAAMC,WAAW,GAAG9C,MAAM,CAACe,IAAP,CAAY8B,YAAZ,CAApB;AAD8H,8BAErGF,IAAI,CAACI,MAAL,CAAYH,UAAZ,CAFqG;AAAA,MAEtHI,KAFsH,yBAEtHA,KAFsH;AAAA,MAE/GC,KAF+G,yBAE/GA,KAF+G;AAG9H,SAAO;AACLD,IAAAA,KAAK,EAALA,KADK;AAELC,IAAAA,KAAK,EAALA,KAFK;AAGLH,IAAAA,WAAW,EAAXA,WAHK;AAILF,IAAAA,UAAU,EAAVA;AAJK,GAAP;AAMD;;AAED,SAASM,yBAAT,CAAmCnD,IAAnC,EAA+CoD,QAA/C,EAAiER,IAAjE,EAAkH;AAChH,MAAI,CAAC5C,IAAI,CAACqD,GAAV,EAAe;AACb,UAAM,IAAIC,KAAJ,CAAU,wBAAV,CAAN;AACD,GAH+G,CAKhH;;;AACA,MAAMC,cAAc,GAAG;AACrBC,IAAAA,EAAE,EAAExD,IAAI,CAACqD,GADY;AAErBI,IAAAA,IAAI,EAAEzD,IAAI,CAACyD,IAFU;AAGrBC,IAAAA,WAAW,EAAE1D,IAAI,CAAC0D,WAHG;AAIrBC,IAAAA,IAAI,EAAE,CAAC;AAAEC,MAAAA,IAAI,EAAE/E,MAAM,CAACgF,EAAf;AAAmBC,MAAAA,IAAI,EAAE9D,IAAI,CAACyD;AAA9B,KAAD,CAJe;AAKrBM,IAAAA,IAAI,EAAE;AACJC,MAAAA,QAAQ,EAAEhE,IAAI,CAAC+D,IAAL,CAAUC,QADhB;AAEJC,MAAAA,KAAK,EAAEjE,IAAI,CAAC+D,IAAL,CAAUE,KAFb;AAGJC,MAAAA,IAAI,EAAElE,IAAI,CAAC+D,IAAL,CAAUG,IAHZ;AAIJC,MAAAA,QAAQ,EAAEnE,IAAI,CAAC+D,IAAL,CAAUI,QAJhB;AAKJC,MAAAA,eAAe,EAAEpE,IAAI,CAAC+D,IAAL,CAAUK;AALvB,KALe;AAYrBhC,IAAAA,KAAK,EAAE/C,UAZc;AAarB8C,IAAAA,SAAS,EAAE7C,cAbU;AAcrB+E,IAAAA,OAAO,EAAErE,IAAI,CAACqE,OAdO;AAerBzD,IAAAA,OAAO,EAAEZ,IAAI,CAACG;AAfO,GAAvB;AAkBA,2BACKoD,cADL;AAEEe,IAAAA,WAAW,EAAE3B,cAAc,CAACC,IAAD,EAAOQ,QAAP,EAAiBG,cAAjB;AAF7B;AAID;;AAED,SAASgB,uBAAT,CAAiCC,UAAjC,EAAyDxE,IAAzD,EAA2F;AACzF,MAAI,CAACwE,UAAU,CAACC,eAAZ,IAA+B,CAACzE,IAAI,CAAC0E,OAAzC,EAAkD;AAChD,UAAM,IAAIpB,KAAJ,CAAU,kDAAV,CAAN;AACD,GAHwF,CAKzF;;;AACA,MAAMqB,YAAkC,GAAG;AACzCnB,IAAAA,EAAE,EAAEtE,oBAAoB,CAACsF,UAAU,CAACC,eAAZ,EAA8BzE,IAAI,CAAC0E,OAAnC,CADiB;AAEzCjB,IAAAA,IAAI,EAAEzD,IAAI,CAACyD,IAF8B;AAGzCC,IAAAA,WAAW,EAAE1D,IAAI,CAAC0D,WAHuB;AAIzCkB,IAAAA,iBAAiB,EAAEJ,UAAU,CAACC,eAJW;AAKzCI,IAAAA,MAAM,EAAG7E,IAAI,CAAC6E,MAL2B;AAMzClB,IAAAA,IAAI,EAAE,CAAC;AAAEC,MAAAA,IAAI,EAAE/E,MAAM,CAACgF,EAAf;AAAmBC,MAAAA,IAAI,EAAE9D,IAAI,CAACyD;AAA9B,KAAD,CANmC;AAOzCM,IAAAA,IAAI,EAAE;AACJC,MAAAA,QAAQ,EAAEhE,IAAI,CAAC+D,IAAL,CAAUC,QADhB;AAEJC,MAAAA,KAAK,EAAEjE,IAAI,CAAC+D,IAAL,CAAUE,KAFb;AAGJC,MAAAA,IAAI,EAAElE,IAAI,CAAC+D,IAAL,CAAUG,IAHZ;AAIJC,MAAAA,QAAQ,EAAEnE,IAAI,CAAC+D,IAAL,CAAUI,QAJhB;AAKJC,MAAAA,eAAe,EAAEpE,IAAI,CAAC+D,IAAL,CAAUK;AALvB,KAPmC;AAczChC,IAAAA,KAAK,EAAE/C,UAdkC;AAezC8C,IAAAA,SAAS,EAAE7C,cAf8B;AAgBzC+E,IAAAA,OAAO,EAAErE,IAAI,CAACqE;AAhB2B,GAA3C;;AAmBA,MAAIrE,IAAI,CAAC8E,IAAL,KAAcvF,QAAQ,CAACwF,KAA3B,EAAkC;AAChCJ,IAAAA,YAAY,CAACK,WAAb,GAA2B;AACzBC,MAAAA,IAAI,EAAGjF,IAAI,CAAC+D,IAAN,CAAyBI,QAAzB,KAAsC3E,aAAa,CAAC0F;AADjC,KAA3B,CADgC,CAIhC;;AACAP,IAAAA,YAAY,CAACZ,IAAb,CAAkBI,QAAlB,GAA6BrF,gBAAgB,CAACqG,GAA9C;AACAR,IAAAA,YAAY,CAACZ,IAAb,CAAkBE,KAAlB,GAA0B,EAA1B;AACAU,IAAAA,YAAY,CAACZ,IAAb,CAAkBC,QAAlB,GAA6B,EAA7B;AACAW,IAAAA,YAAY,CAACZ,IAAb,CAAkBK,eAAlB,GAAoCO,YAAY,CAACZ,IAAb,CAAkBK,eAAlB,CAAkCnD,GAAlC,CAAsC,UAAAmE,cAAc;AAAA,+BACnFA,cADmF;AAEtFC,QAAAA,aAAa,EAAE,EAFuE;AAGtFC,QAAAA,gBAAgB,EAAE;AAHoE;AAAA,KAApD,CAApC;AAKD;;AAED,SAAOX,YAAP;AACD;;SAEcY,sB;;;;;qFAAf,kBAAsCvF,IAAtC;AAAA;AAAA;AAAA;AAAA;AAAA;AACQG,YAAAA,QADR,qBACwBH,IAAI,CAACG,QAD7B;;AAAA,gBAEOH,IAAI,CAACG,QAAL,CAAcd,UAAd,CAFP;AAAA;AAAA;AAAA;;AAAA;AAAA,mBAG+BK,qBAAqB,CAACM,IAAD,CAHpD;;AAAA;AAGU2E,YAAAA,YAHV;AAIIxE,YAAAA,QAAQ,CAACd,UAAD,CAAR,GAAuBsF,YAAY,CAAC9E,IAApC;;AAJJ;AAAA,8CAOSM,QAPT;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;SAUeqF,oB;;;;;mFAAf,kBAAoCxF,IAApC,EAAgDM,mBAAhD;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAC+BmF,OAAO,CAACC,GAAR,CAAY,CACvCpF,mBAAmB,CAACO,aAApB,CAAkCb,IAAI,CAACG,QAAvC,CADuC,EAEvC,CAACH,IAAI,CAACG,QAAL,CAAcd,UAAd,CAAD,GAA6BM,aAAa,CAACK,IAAD,CAA1C,GAAmD,IAFZ,CAAZ,CAD/B;;AAAA;AAAA;AAAA;AACSwC,YAAAA,KADT;AACgBJ,YAAAA,KADhB;AAKEI,YAAAA,KAAK,CAACnD,UAAD,CAAL,GAAoB+C,KAApB,aAAoBA,KAApB,cAAoBA,KAApB,GAA6BI,KAAK,CAACnD,UAAD,CAAlC;AALF,8CAMSmD,KANT;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AASA,gBAAsBmD,eAAtB;AAAA;AAAA;;;8EAAO,kBACLC,MADK,EAELtF,mBAFK,EAGLkE,UAHK,EAILxE,IAJK,EAKL4C,IALK,EAMLQ,QANK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAQeoC,oBAAoB,CAACxF,IAAD,EAAOM,mBAAP,CARnC;;AAAA;AAQCe,YAAAA,KARD;AAAA;AAAA,mBASelC,gBAAgB,CAACkC,KAAD,CAT/B;;AAAA;AASCmB,YAAAA,KATD;AAUCqD,YAAAA,QAVD,GAUYjD,IAAI,IAAIQ,QAAR,GAAmBD,yBAAyB,CAACnD,IAAD,EAAOoD,QAAP,EAAiBR,IAAjB,CAA5C,GAAqE2B,uBAAuB,CAACC,UAAD,EAAaxE,IAAb,CAVxG;AAAA,8CAWE4F,MAAM,CAACE,WAAP,CAAmB;AACxBhB,cAAAA,IAAI,EAAE/F,UAAU,CAACgH,QADO;AAExBC,cAAAA,QAAQ,EAAE,CAACH,QAAQ,CAACrC,EAAV,CAFc;AAGxBqC,cAAAA,QAAQ,EAARA,QAHwB;AAIxBrD,cAAAA,KAAK,EAALA,KAJwB;AAKxByD,cAAAA,SAAS,EAAEC,IAAI,CAACC,GAAL;AALa,aAAnB,CAXF;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAoBP,gBAAsBC,uBAAtB;AAAA;AAAA;;;sFAAO,kBACLR,MADK,EAELtF,mBAFK,EAGLkE,UAHK,EAILxE,IAJK;AAAA;AAAA;AAAA;AAAA;AAAA,8CAME2F,eAAe,CAACC,MAAD,EAAStF,mBAAT,EAA8BkE,UAA9B,EAA0CxE,IAA1C,CANjB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AASP,gBAAsBqG,iBAAtB;AAAA;AAAA;;;gFAAO,kBACLT,MADK,EAELtF,mBAFK,EAGLkE,UAHK,EAILxE,IAJK,EAKL4C,IALK,EAMLQ,QANK;AAAA;AAAA;AAAA;AAAA;AAAA,8CAQEuC,eAAe,CAACC,MAAD,EAAStF,mBAAT,EAA8BkE,UAA9B,EAA0CxE,IAA1C,EAAgD4C,IAAhD,EAAsDQ,QAAtD,CARjB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G;;;;AAWP,gBAAsBkD,gCAAtB;AAAA;AAAA;;;+FAAO,kBACL9B,UADK,EAELxE,IAFK;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGLuG,YAAAA,WAHK,8DAGS9G,iBAAiB,CAAC+G,EAH3B;AAAA;AAAA,mBAKgBjB,sBAAsB,CAACvF,IAAD,CALtC;;AAAA;AAKCoB,YAAAA,MALD;AAMCR,YAAAA,OAND,GAMWX,MAAM,CAACe,IAAP,CAAYI,MAAZ,EAAoBH,GAApB,CAAwB,UAAAwF,IAAI;AAAA,qBAAK;AAAEA,gBAAAA,IAAI,EAAJA,IAAF;AAAQ5G,gBAAAA,IAAI,EAAEuB,MAAM,CAACqF,IAAD;AAApB,eAAL;AAAA,aAA5B,CANX;AAOCZ,YAAAA,QAPD,GAOYtB,uBAAuB,CAACC,UAAD,EAAaxE,IAAb,CAPnC;;AAAA,kBAQDuG,WAAW,KAAK9G,iBAAiB,CAACiH,EARjC;AAAA;AAAA;AAAA;;AAAA;AAAA,mBASWzH,wCAAwC,CAAC2B,OAAD,EAAUiF,QAAV,CATnD;;AAAA;AAAA,6DASwEhG,IATxE;;AAAA;AAAA;AAAA,mBAWWb,4BAA4B,CAAC4B,OAAD,EAAUiF,QAAV,CAXvC;;AAAA;AAAA,6DAW4DhG,IAX5D;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,G","sourcesContent":["import { Locale, Rarity, ThirdPartyWearable, WearableCategory, WearableRepresentation } from '@dcl/schemas'\nimport { CatalystClient, DeploymentPreparationData } from 'dcl-catalyst-client'\nimport { MerkleDistributorInfo } from '@dcl/content-hash-tree/dist/types'\nimport { EntityType } from 'dcl-catalyst-commons'\nimport { calculateMultipleHashesADR32, calculateMultipleHashesADR32LegacyQmHash } from '@dcl/hashing'\nimport { BuilderAPI } from 'lib/api/builder'\nimport { buildCatalystItemURN } from 'lib/urn'\nimport { makeContentFiles, computeHashes } from 'modules/deployment/contentUtils'\nimport { Collection } from 'modules/collection/types'\nimport { Item, IMAGE_PATH, THUMBNAIL_PATH, StandardCatalystItem, ItemType, EmoteData, EmoteCategory, EntityHashingType } from './types'\nimport { generateCatalystImage, generateImage } from './utils'\n\n/**\n * Checks if a hash was generated using an older algorithm.\n *\n * @param hash - A hash.\n * @returns true if the hash is from an older version.\n */\nexport function isOldHash(hash: string): boolean {\n  return hash.startsWith('Qm')\n}\n\n/**\n * Checks if an item has content hashes generated using an older algorithm.\n *\n * @param item - An item.\n * @returns true if the item has older hashes.\n */\nexport function hasOldHashedContents(item: Item): boolean {\n  return Object.values(item.contents).some(hash => isOldHash(hash))\n}\n\n/**\n * Takes a map of contents (file name -> hash), downloads the contents that are hashed with an older algorithm\n * and builds a new map that contains the content and their hash.\n *\n * @param contents - The contents to be updated.\n * @returns A map containing only the contents that have been updated and re-hashed.\n */\nexport async function reHashOlderContents(\n  contents: Record<string, string>,\n  legacyBuilderClient: BuilderAPI\n): Promise<Record<string, { hash: string; content: Blob }>> {\n  const contentsWithOldHashes = Object.fromEntries(Object.entries(contents).filter(([_, content]) => isOldHash(content)))\n  const contentOfOldHashedFiles = await legacyBuilderClient.fetchContents(contentsWithOldHashes)\n  const newHashesOfOldHashedFiles = await computeHashes(contentOfOldHashedFiles)\n  return Object.fromEntries(\n    Object.keys(contentsWithOldHashes).map(key => [key, { hash: newHashesOfOldHashedFiles[key], content: contentOfOldHashedFiles[key] }])\n  )\n}\n\n/**\n * Gets an array of unique files based on their hashes.\n *\n * @param hashes - The record of names->hashes.\n * @param blobs - The record of names->blobs.\n */\nfunction getUniqueFiles(hashes: Record<string, string>, blobs: Record<string, Blob>): Array<Blob> {\n  const uniqueFileHashes: Array<string> = [...new Set(Object.values(hashes))]\n  const inverseFileHashesRecord = Object.keys(hashes).reduce((obj: Record<string, string>, key: string) => {\n    obj[hashes[key]] = key\n    return obj\n  }, {})\n  return uniqueFileHashes.map(hash => blobs[inverseFileHashesRecord[hash]])\n}\n\n/**\n * Calculates the final size (with the already stored content and the new one) of the contents of an item.\n * All the files in newContents must also be in the item's contents in both name and hash.\n *\n * @param item - An item that contains the old and the new hashed content.\n * @param newContents - The new content that is going to be added to the item.\n */\nexport async function calculateFinalSize(item: Item, newContents: Record<string, Blob>, legacyBuilderClient: BuilderAPI): Promise<number> {\n  const newHashes = await computeHashes(newContents)\n  const filesToDownload: Record<string, string> = {}\n  for (const fileName in item.contents) {\n    if (!newHashes[fileName] || item.contents[fileName] !== newHashes[fileName]) {\n      filesToDownload[fileName] = item.contents[fileName]\n    }\n  }\n\n  const blobs = await legacyBuilderClient.fetchContents(filesToDownload)\n  const allBlobs = { ...newContents, ...blobs }\n  const allHashes = { ...newHashes, ...filesToDownload }\n\n  let imageSize = 0\n  // Only generate the catalyst image if there isn't one already\n  if (!allBlobs[IMAGE_PATH]) {\n    try {\n      const image = await generateImage(item, { thumbnail: allBlobs[THUMBNAIL_PATH] })\n      imageSize = image.size\n    } catch (error) {}\n  }\n\n  const uniqueFiles = getUniqueFiles(allHashes, allBlobs)\n  return imageSize + calculateFilesSize(uniqueFiles)\n}\n\n/**\n * Sums the sizes of an array of blobs.\n *\n * @param files - An array of blobs.\n */\nfunction calculateFilesSize(files: Array<Blob>) {\n  return files.reduce((total, blob) => blob.size + total, 0)\n}\n\nfunction getMerkleProof(tree: MerkleDistributorInfo, entityHash: string, entityValues: Omit<ThirdPartyWearable, 'merkleProof'>) {\n  const hashingKeys = Object.keys(entityValues)\n  const { index, proof } = tree.proofs[entityHash]\n  return {\n    index,\n    proof,\n    hashingKeys,\n    entityHash\n  }\n}\n\nfunction buildTPItemEntityMetadata(item: Item, itemHash: string, tree: MerkleDistributorInfo): ThirdPartyWearable {\n  if (!item.urn) {\n    throw new Error('Item does not have URN')\n  }\n\n  // The order of the metadata properties can't be changed. Changing it will result in a different content hash.\n  const baseEntityData = {\n    id: item.urn,\n    name: item.name,\n    description: item.description,\n    i18n: [{ code: Locale.EN, text: item.name }],\n    data: {\n      replaces: item.data.replaces as WearableCategory[],\n      hides: item.data.hides as WearableCategory[],\n      tags: item.data.tags,\n      category: item.data.category as WearableCategory,\n      representations: item.data.representations as WearableRepresentation[]\n    },\n    image: IMAGE_PATH,\n    thumbnail: THUMBNAIL_PATH,\n    metrics: item.metrics,\n    content: item.contents\n  }\n\n  return {\n    ...baseEntityData,\n    merkleProof: getMerkleProof(tree, itemHash, baseEntityData)\n  }\n}\n\nfunction buildItemEntityMetadata(collection: Collection, item: Item): StandardCatalystItem {\n  if (!collection.contractAddress || !item.tokenId) {\n    throw new Error('You need the collection and item to be published')\n  }\n\n  // The order of the metadata properties can't be changed. Changing it will result in a different content hash.\n  const catalystItem: StandardCatalystItem = {\n    id: buildCatalystItemURN(collection.contractAddress!, item.tokenId!),\n    name: item.name,\n    description: item.description,\n    collectionAddress: collection.contractAddress!,\n    rarity: (item.rarity! as unknown) as Rarity,\n    i18n: [{ code: Locale.EN, text: item.name }],\n    data: {\n      replaces: item.data.replaces as WearableCategory[],\n      hides: item.data.hides as WearableCategory[],\n      tags: item.data.tags,\n      category: item.data.category as WearableCategory,\n      representations: item.data.representations as WearableRepresentation[]\n    },\n    image: IMAGE_PATH,\n    thumbnail: THUMBNAIL_PATH,\n    metrics: item.metrics\n  }\n\n  if (item.type === ItemType.EMOTE) {\n    catalystItem.emoteDataV0 = {\n      loop: (item.data as EmoteData).category === EmoteCategory.LOOP\n    }\n    // add missing properties from wearable schema so catalyst wont reject the deployment\n    catalystItem.data.category = WearableCategory.HAT\n    catalystItem.data.hides = []\n    catalystItem.data.replaces = []\n    catalystItem.data.representations = catalystItem.data.representations.map(representation => ({\n      ...representation,\n      overrideHides: [],\n      overrideReplaces: []\n    }))\n  }\n\n  return catalystItem\n}\n\nasync function buildItemEntityContent(item: Item): Promise<Record<string, string>> {\n  const contents = { ...item.contents }\n  if (!item.contents[IMAGE_PATH]) {\n    const catalystItem = await generateCatalystImage(item)\n    contents[IMAGE_PATH] = catalystItem.hash\n  }\n\n  return contents\n}\n\nasync function buildItemEntityBlobs(item: Item, legacyBuilderClient: BuilderAPI): Promise<Record<string, Blob>> {\n  const [files, image] = await Promise.all([\n    legacyBuilderClient.fetchContents(item.contents),\n    !item.contents[IMAGE_PATH] ? generateImage(item) : null\n  ])\n  files[IMAGE_PATH] = image ?? files[IMAGE_PATH]\n  return files\n}\n\nexport async function buildItemEntity(\n  client: CatalystClient,\n  legacyBuilderClient: BuilderAPI,\n  collection: Collection,\n  item: Item,\n  tree?: MerkleDistributorInfo,\n  itemHash?: string\n): Promise<DeploymentPreparationData> {\n  const blobs = await buildItemEntityBlobs(item, legacyBuilderClient)\n  const files = await makeContentFiles(blobs)\n  const metadata = tree && itemHash ? buildTPItemEntityMetadata(item, itemHash, tree) : buildItemEntityMetadata(collection, item)\n  return client.buildEntity({\n    type: EntityType.WEARABLE,\n    pointers: [metadata.id],\n    metadata,\n    files,\n    timestamp: Date.now()\n  })\n}\n\nexport async function buildStandardItemEntity(\n  client: CatalystClient,\n  legacyBuilderClient: BuilderAPI,\n  collection: Collection,\n  item: Item\n): Promise<DeploymentPreparationData> {\n  return buildItemEntity(client, legacyBuilderClient, collection, item)\n}\n\nexport async function buildTPItemEntity(\n  client: CatalystClient,\n  legacyBuilderClient: BuilderAPI,\n  collection: Collection,\n  item: Item,\n  tree: MerkleDistributorInfo,\n  itemHash: string\n): Promise<DeploymentPreparationData> {\n  return buildItemEntity(client, legacyBuilderClient, collection, item, tree, itemHash)\n}\n\nexport async function buildStandardWearableContentHash(\n  collection: Collection,\n  item: Item,\n  hashingType = EntityHashingType.V1\n): Promise<string> {\n  const hashes = await buildItemEntityContent(item)\n  const content = Object.keys(hashes).map(file => ({ file, hash: hashes[file] }))\n  const metadata = buildItemEntityMetadata(collection, item)\n  if (hashingType === EntityHashingType.V0) {\n    return (await calculateMultipleHashesADR32LegacyQmHash(content, metadata)).hash\n  } else {\n    return (await calculateMultipleHashesADR32(content, metadata)).hash\n  }\n}\n"]},"metadata":{},"sourceType":"module"}