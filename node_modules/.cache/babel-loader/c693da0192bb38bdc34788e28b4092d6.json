{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar _possibleConstructorReturn = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/possibleConstructorReturn\");\n\nvar _getPrototypeOf = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/getPrototypeOf\");\n\nvar _inherits = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/inherits\");\n\nvar leftPad = require('left-pad');\n\nvar whilst = require('async/whilst');\n\nvar waterfall = require('async/waterfall');\n\nvar dagPB = require('ipld-dag-pb');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar DAGLink = dagPB.DAGLink;\nvar DAGNode = dagPB.DAGNode;\n\nvar multihashing = require('multihashing-async');\n\nvar Dir = require('./dir');\n\nvar persist = require('../utils/persist');\n\nvar toPull = require('async-iterator-to-pull-stream');\n\nvar pull = require('pull-stream/pull');\n\nvar onEnd = require('pull-stream/sinks/on-end');\n\nvar asyncMap = require('pull-stream/throughs/async-map');\n\nvar Bucket = require('hamt-sharding');\n\nvar hashFn = function hashFn(value) {\n  return new Promise(function (resolve, reject) {\n    multihashing(value, 'murmur3-128', function (err, hash) {\n      if (err) {\n        reject(err);\n      } else {\n        // Multihashing inserts preamble of 2 bytes. Remove it.\n        // Also, murmur3 outputs 128 bit but, accidently, IPFS Go's\n        // implementation only uses the first 64, so we must do the same\n        // for parity..\n        var justHash = hash.slice(2, 10);\n        var length = justHash.length;\n        var result = Buffer.alloc(length); // TODO: invert buffer because that's how Go impl does it\n\n        for (var i = 0; i < length; i++) {\n          result[length - i - 1] = justHash[i];\n        }\n\n        resolve(result);\n      }\n    });\n  });\n};\n\nhashFn.code = 0x22; // TODO: get this from multihashing-async?\n\nvar defaultOptions = {\n  hashFn: hashFn\n};\n\nvar DirSharded = /*#__PURE__*/function (_Dir) {\n  _inherits(DirSharded, _Dir);\n\n  function DirSharded(props, _options) {\n    var _this;\n\n    _classCallCheck(this, DirSharded);\n\n    var options = Object.assign({}, defaultOptions, _options);\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(DirSharded).call(this, props, options));\n    _this._bucket = Bucket(options);\n    return _this;\n  }\n\n  _createClass(DirSharded, [{\n    key: \"put\",\n    value: function () {\n      var _put = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(name, value, callback) {\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                _context.prev = 0;\n                _context.next = 3;\n                return this._bucket.put(name, value);\n\n              case 3:\n                return _context.abrupt(\"return\", callback());\n\n              case 6:\n                _context.prev = 6;\n                _context.t0 = _context[\"catch\"](0);\n                return _context.abrupt(\"return\", callback(_context.t0));\n\n              case 9:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[0, 6]]);\n      }));\n\n      function put(_x, _x2, _x3) {\n        return _put.apply(this, arguments);\n      }\n\n      return put;\n    }()\n  }, {\n    key: \"get\",\n    value: function () {\n      var _get = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(name, callback) {\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                _context2.prev = 0;\n                _context2.t0 = callback;\n                _context2.next = 4;\n                return this._bucket.get(name);\n\n              case 4:\n                _context2.t1 = _context2.sent;\n                return _context2.abrupt(\"return\", (0, _context2.t0)(null, _context2.t1));\n\n              case 8:\n                _context2.prev = 8;\n                _context2.t2 = _context2[\"catch\"](0);\n                return _context2.abrupt(\"return\", callback(_context2.t2));\n\n              case 11:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this, [[0, 8]]);\n      }));\n\n      function get(_x4, _x5) {\n        return _get.apply(this, arguments);\n      }\n\n      return get;\n    }()\n  }, {\n    key: \"childCount\",\n    value: function childCount() {\n      return this._bucket.leafCount();\n    }\n  }, {\n    key: \"directChildrenCount\",\n    value: function directChildrenCount() {\n      return this._bucket.childrenCount();\n    }\n  }, {\n    key: \"onlyChild\",\n    value: function onlyChild(callback) {\n      try {\n        return callback(null, this._bucket.onlyChild());\n      } catch (err) {\n        return callback(err);\n      }\n    }\n  }, {\n    key: \"eachChildSeries\",\n    value: function eachChildSeries(iterator, callback) {\n      pull(toPull(this._bucket.eachLeafSeries()), asyncMap(function (child, cb) {\n        iterator(child.key, child.value, cb);\n      }), onEnd(callback));\n    }\n  }, {\n    key: \"flush\",\n    value: function flush(path, ipld, source, callback) {\n      var _this2 = this;\n\n      _flush(this._options, this._bucket, path, ipld, source, function (err, results) {\n        if (err) {\n          return callback(err);\n        } else {\n          _this2.multihash = results.cid.buffer;\n          _this2.size = results.node.size;\n        }\n\n        callback(null, results);\n      });\n    }\n  }]);\n\n  return DirSharded;\n}(Dir);\n\nmodule.exports = createDirSharded;\nmodule.exports.hashFn = hashFn;\n\nfunction createDirSharded(props, _options) {\n  return new DirSharded(props, _options);\n}\n\nfunction _flush(options, bucket, path, ipld, source, callback) {\n  var children = bucket._children; // TODO: intromission\n\n  var index = 0;\n  var links = [];\n  whilst(function () {\n    return index < children.length;\n  }, function (callback) {\n    var child = children.get(index);\n\n    if (child) {\n      collectChild(child, index, function (err) {\n        index++;\n        callback(err);\n      });\n    } else {\n      index++;\n      callback();\n    }\n  }, function (err) {\n    if (err) {\n      callback(err);\n      return; // early\n    }\n\n    haveLinks(links, callback);\n  });\n\n  function collectChild(child, index, callback) {\n    var labelPrefix = leftPad(index.toString(16).toUpperCase(), 2, '0');\n\n    if (Bucket.isBucket(child)) {\n      _flush(options, child, path, ipld, null, function (err, _ref) {\n        var cid = _ref.cid,\n            node = _ref.node;\n\n        if (err) {\n          callback(err);\n          return; // early\n        }\n\n        links.push(new DAGLink(labelPrefix, node.size, cid));\n        callback();\n      });\n    } else {\n      var value = child.value;\n      var label = labelPrefix + child.key;\n      links.push(new DAGLink(label, value.size, value.multihash));\n      callback();\n    }\n  }\n\n  function haveLinks(links, callback) {\n    // go-ipfs uses little endian, that's why we have to\n    // reverse the bit field before storing it\n    var data = Buffer.from(children.bitField().reverse());\n    var dir = new UnixFS('hamt-sharded-directory', data);\n    dir.fanout = bucket.tableSize();\n    dir.hashType = options.hashFn.code;\n    waterfall([function (cb) {\n      return DAGNode.create(dir.marshal(), links, cb);\n    }, function (node, cb) {\n      return persist(node, ipld, options, cb);\n    }, function (_ref2, cb) {\n      var cid = _ref2.cid,\n          node = _ref2.node;\n      var pushable = {\n        path: path,\n        size: node.size,\n        multihash: cid.buffer\n      };\n\n      if (source) {\n        source.push(pushable);\n      }\n\n      cb(null, {\n        cid: cid,\n        node: node\n      });\n    }], callback);\n  }\n}","map":null,"metadata":{},"sourceType":"script"}