{"ast":null,"code":"\"use strict\";\n\nvar _slicedToArray = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/slicedToArray\");\n\nvar _regeneratorRuntime = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _objectSpread = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/objectSpread\");\n\nvar _asyncToGenerator = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/opt/work/NZ_test/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = it.call(o); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nvar __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  Object.defineProperty(o, k2, {\n    enumerable: true,\n    get: function get() {\n      return m[k];\n    }\n  });\n} : function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\n\nvar __setModuleDefault = this && this.__setModuleDefault || (Object.create ? function (o, v) {\n  Object.defineProperty(o, \"default\", {\n    enumerable: true,\n    value: v\n  });\n} : function (o, v) {\n  o[\"default\"] = v;\n});\n\nvar __importStar = this && this.__importStar || function (mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) {\n    if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  }\n\n  __setModuleDefault(result, mod);\n\n  return result;\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.DeploymentBuilder = void 0;\n\nvar hashing = __importStar(require(\"@dcl/hashing\"));\n\nvar hashing_1 = require(\"@dcl/hashing\");\n\nvar dcl_catalyst_commons_1 = require(\"dcl-catalyst-commons\");\n\nvar DeploymentBuilder = /*#__PURE__*/function () {\n  function DeploymentBuilder() {\n    _classCallCheck(this, DeploymentBuilder);\n  }\n\n  _createClass(DeploymentBuilder, null, [{\n    key: \"buildEntityAndFile\",\n\n    /**\n     * Take all the entity's data, build the entity file with it, and calculate its id\n     */\n    value: function () {\n      var _buildEntityAndFile = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(_ref) {\n        var type, pointers, timestamp, content, metadata, entity, usedFilenames, _iterator, _step, a, lowerCasedFileName, entityFile, entityId, entityWithId;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                type = _ref.type, pointers = _ref.pointers, timestamp = _ref.timestamp, content = _ref.content, metadata = _ref.metadata;\n\n                if (!(pointers.length === 0)) {\n                  _context.next = 3;\n                  break;\n                }\n\n                throw new Error(\"All entities must have at least one pointer.\");\n\n              case 3:\n                entity = {\n                  // default version is V3\n                  version: dcl_catalyst_commons_1.EntityVersion.V3,\n                  type: type,\n                  pointers: pointers,\n                  timestamp: timestamp,\n                  content: content,\n                  metadata: metadata\n                }; // prevent duplicated file names\n\n                if (!content) {\n                  _context.next = 25;\n                  break;\n                }\n\n                usedFilenames = new Set();\n                _iterator = _createForOfIteratorHelper(content);\n                _context.prev = 7;\n\n                _iterator.s();\n\n              case 9:\n                if ((_step = _iterator.n()).done) {\n                  _context.next = 17;\n                  break;\n                }\n\n                a = _step.value;\n                lowerCasedFileName = a.file.toLowerCase();\n\n                if (!usedFilenames.has(lowerCasedFileName)) {\n                  _context.next = 14;\n                  break;\n                }\n\n                throw new Error(\"Error creating the deployable entity: Decentraland's file system is case insensitive, the file \".concat(JSON.stringify(a.file), \" is repeated\"));\n\n              case 14:\n                usedFilenames.add(lowerCasedFileName);\n\n              case 15:\n                _context.next = 9;\n                break;\n\n              case 17:\n                _context.next = 22;\n                break;\n\n              case 19:\n                _context.prev = 19;\n                _context.t0 = _context[\"catch\"](7);\n\n                _iterator.e(_context.t0);\n\n              case 22:\n                _context.prev = 22;\n\n                _iterator.f();\n\n                return _context.finish(22);\n\n              case 25:\n                entityFile = new TextEncoder().encode(JSON.stringify(entity));\n                _context.next = 28;\n                return (0, hashing_1.hashV1)(entityFile);\n\n              case 28:\n                entityId = _context.sent;\n                entityWithId = _objectSpread({\n                  id: entityId\n                }, entity);\n                return _context.abrupt(\"return\", {\n                  entity: entityWithId,\n                  entityFile: entityFile\n                });\n\n              case 31:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, null, [[7, 19, 22, 25]]);\n      }));\n\n      function buildEntityAndFile(_x) {\n        return _buildEntityAndFile.apply(this, arguments);\n      }\n\n      return buildEntityAndFile;\n    }()\n    /**\n     * As part of the deployment process, an entity has to be built. In this method, we are building it, based on the data provided.\n     * After the entity is built, the user will have to sign the entity id, to prove they are actually who they say they are.\n     */\n\n  }, {\n    key: \"buildEntity\",\n    value: function () {\n      var _buildEntity = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(_ref2) {\n        var type, pointers, files, metadata, timestamp, contentFiles, allInfo, hashesByKey, filesByHash;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                type = _ref2.type, pointers = _ref2.pointers, files = _ref2.files, metadata = _ref2.metadata, timestamp = _ref2.timestamp;\n                // Reorder input\n                contentFiles = Array.from(files ? files : []).map(function (_ref3) {\n                  var _ref4 = _slicedToArray(_ref3, 2),\n                      key = _ref4[0],\n                      content = _ref4[1];\n\n                  return {\n                    key: key,\n                    content: content\n                  };\n                }); // Calculate hashes\n\n                _context3.next = 4;\n                return Promise.all(contentFiles.map( /*#__PURE__*/function () {\n                  var _ref6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(_ref5) {\n                    var key, content;\n                    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n                      while (1) {\n                        switch (_context2.prev = _context2.next) {\n                          case 0:\n                            key = _ref5.key, content = _ref5.content;\n                            _context2.t0 = key;\n                            _context2.t1 = content;\n                            _context2.next = 5;\n                            return hashing.hashV1(content);\n\n                          case 5:\n                            _context2.t2 = _context2.sent;\n                            return _context2.abrupt(\"return\", {\n                              key: _context2.t0,\n                              content: _context2.t1,\n                              hash: _context2.t2\n                            });\n\n                          case 7:\n                          case \"end\":\n                            return _context2.stop();\n                        }\n                      }\n                    }, _callee2);\n                  }));\n\n                  return function (_x3) {\n                    return _ref6.apply(this, arguments);\n                  };\n                }()));\n\n              case 4:\n                allInfo = _context3.sent;\n                hashesByKey = new Map(allInfo.map(function (_ref7) {\n                  var hash = _ref7.hash,\n                      key = _ref7.key;\n                  return [key, hash];\n                }));\n                filesByHash = new Map(allInfo.map(function (_ref8) {\n                  var hash = _ref8.hash,\n                      content = _ref8.content;\n                  return [hash, content];\n                }));\n                return _context3.abrupt(\"return\", DeploymentBuilder.buildEntityInternal(type, pointers, {\n                  hashesByKey: hashesByKey,\n                  filesByHash: filesByHash,\n                  metadata: metadata,\n                  timestamp: timestamp\n                }));\n\n              case 8:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3);\n      }));\n\n      function buildEntity(_x2) {\n        return _buildEntity.apply(this, arguments);\n      }\n\n      return buildEntity;\n    }()\n    /**\n     * In cases where we don't need upload content files, we can simply generate the new entity. We can still use already uploaded hashes on this new entity.\n     */\n\n  }, {\n    key: \"buildEntityWithoutNewFiles\",\n    value: function () {\n      var _buildEntityWithoutNewFiles = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(_ref9) {\n        var type, pointers, hashesByKey, metadata, timestamp;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                type = _ref9.type, pointers = _ref9.pointers, hashesByKey = _ref9.hashesByKey, metadata = _ref9.metadata, timestamp = _ref9.timestamp;\n                return _context4.abrupt(\"return\", DeploymentBuilder.buildEntityInternal(type, pointers, {\n                  hashesByKey: hashesByKey,\n                  metadata: metadata,\n                  timestamp: timestamp\n                }));\n\n              case 2:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4);\n      }));\n\n      function buildEntityWithoutNewFiles(_x4) {\n        return _buildEntityWithoutNewFiles.apply(this, arguments);\n      }\n\n      return buildEntityWithoutNewFiles;\n    }()\n  }, {\n    key: \"buildEntityInternal\",\n    value: function () {\n      var _buildEntityInternal = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(type, pointers, options) {\n        var hashesByKey, entityContent, timestamp, _yield$DeploymentBuil, entity, entityFile, filesByHash;\n\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                if (!(pointers.length === 0)) {\n                  _context5.next = 2;\n                  break;\n                }\n\n                throw new Error(\"All entities must have at least one pointer.\");\n\n              case 2:\n                // Re-organize the hashes\n                hashesByKey = (options === null || options === void 0 ? void 0 : options.hashesByKey) ? options === null || options === void 0 ? void 0 : options.hashesByKey : new Map();\n                entityContent = Array.from(hashesByKey.entries()).map(function (_ref10) {\n                  var _ref11 = _slicedToArray(_ref10, 2),\n                      key = _ref11[0],\n                      hash = _ref11[1];\n\n                  return {\n                    file: key,\n                    hash: hash\n                  };\n                }); // Calculate timestamp if necessary\n\n                timestamp = (options === null || options === void 0 ? void 0 : options.timestamp) ? options === null || options === void 0 ? void 0 : options.timestamp : Date.now(); // Build entity file\n\n                _context5.next = 7;\n                return DeploymentBuilder.buildEntityAndFile({\n                  type: type,\n                  pointers: pointers,\n                  timestamp: timestamp,\n                  content: entityContent,\n                  metadata: options === null || options === void 0 ? void 0 : options.metadata\n                });\n\n              case 7:\n                _yield$DeploymentBuil = _context5.sent;\n                entity = _yield$DeploymentBuil.entity;\n                entityFile = _yield$DeploymentBuil.entityFile;\n                // Add entity file to content files\n                filesByHash = (options === null || options === void 0 ? void 0 : options.filesByHash) ? options.filesByHash : new Map();\n                filesByHash.set(entity.id, entityFile);\n                return _context5.abrupt(\"return\", {\n                  files: filesByHash,\n                  entityId: entity.id\n                });\n\n              case 13:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5);\n      }));\n\n      function buildEntityInternal(_x5, _x6, _x7) {\n        return _buildEntityInternal.apply(this, arguments);\n      }\n\n      return buildEntityInternal;\n    }()\n  }]);\n\n  return DeploymentBuilder;\n}();\n\nexports.DeploymentBuilder = DeploymentBuilder;","map":null,"metadata":{},"sourceType":"script"}