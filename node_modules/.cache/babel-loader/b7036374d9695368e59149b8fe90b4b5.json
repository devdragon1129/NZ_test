{"ast":null,"code":"import { __decorate, __extends } from \"tslib\";\nimport { serialize, SerializationHelper } from \"../../../Misc/decorators\";\nimport { Observable } from \"../../../Misc/observable\";\nimport { Logger } from \"../../../Misc/logger\";\nimport { Texture } from \"../../../Materials/Textures/texture\";\nimport { GlowLayer } from \"../../../Layers/glowLayer\";\nimport { SharpenPostProcess } from \"../../../PostProcesses/sharpenPostProcess\";\nimport { ImageProcessingPostProcess } from \"../../../PostProcesses/imageProcessingPostProcess\";\nimport { ChromaticAberrationPostProcess } from \"../../../PostProcesses/chromaticAberrationPostProcess\";\nimport { GrainPostProcess } from \"../../../PostProcesses/grainPostProcess\";\nimport { FxaaPostProcess } from \"../../../PostProcesses/fxaaPostProcess\";\nimport { PostProcessRenderPipeline } from \"../../../PostProcesses/RenderPipeline/postProcessRenderPipeline\";\nimport { PostProcessRenderEffect } from \"../../../PostProcesses/RenderPipeline/postProcessRenderEffect\";\nimport { DepthOfFieldEffect, DepthOfFieldEffectBlurLevel } from \"../../../PostProcesses/depthOfFieldEffect\";\nimport { BloomEffect } from \"../../../PostProcesses/bloomEffect\";\nimport { _TypeStore } from '../../../Misc/typeStore';\nimport { EngineStore } from \"../../../Engines/engineStore\";\nimport \"../../../PostProcesses/RenderPipeline/postProcessRenderPipelineManagerSceneComponent\";\n/**\r\n * The default rendering pipeline can be added to a scene to apply common post processing effects such as anti-aliasing or depth of field.\r\n * See https://doc.babylonjs.com/how_to/using_default_rendering_pipeline\r\n */\n\nvar DefaultRenderingPipeline =\n/** @class */\nfunction (_super) {\n  __extends(DefaultRenderingPipeline, _super);\n  /**\r\n   * @constructor\r\n   * @param name - The rendering pipeline name (default: \"\")\r\n   * @param hdr - If high dynamic range textures should be used (default: true)\r\n   * @param scene - The scene linked to this pipeline (default: the last created scene)\r\n   * @param cameras - The array of cameras that the rendering pipeline will be attached to (default: scene.cameras)\r\n   * @param automaticBuild - if false, you will have to manually call prepare() to update the pipeline (default: true)\r\n   */\n\n\n  function DefaultRenderingPipeline(name, hdr, scene, cameras, automaticBuild) {\n    if (name === void 0) {\n      name = \"\";\n    }\n\n    if (hdr === void 0) {\n      hdr = true;\n    }\n\n    if (scene === void 0) {\n      scene = EngineStore.LastCreatedScene;\n    }\n\n    if (automaticBuild === void 0) {\n      automaticBuild = true;\n    }\n\n    var _this = _super.call(this, scene.getEngine(), name) || this;\n\n    _this._camerasToBeAttached = [];\n    /**\r\n     * ID of the sharpen post process,\r\n     */\n\n    _this.SharpenPostProcessId = \"SharpenPostProcessEffect\";\n    /**\r\n     * @ignore\r\n     * ID of the image processing post process;\r\n     */\n\n    _this.ImageProcessingPostProcessId = \"ImageProcessingPostProcessEffect\";\n    /**\r\n     * @ignore\r\n     * ID of the Fast Approximate Anti-Aliasing post process;\r\n     */\n\n    _this.FxaaPostProcessId = \"FxaaPostProcessEffect\";\n    /**\r\n     * ID of the chromatic aberration post process,\r\n     */\n\n    _this.ChromaticAberrationPostProcessId = \"ChromaticAberrationPostProcessEffect\";\n    /**\r\n     * ID of the grain post process\r\n     */\n\n    _this.GrainPostProcessId = \"GrainPostProcessEffect\";\n    /**\r\n     * Glow post process which adds a glow to emissive areas of the image\r\n     */\n\n    _this._glowLayer = null;\n    /**\r\n     * Animations which can be used to tweak settings over a period of time\r\n     */\n\n    _this.animations = [];\n    _this._imageProcessingConfigurationObserver = null; // Values\n\n    _this._sharpenEnabled = false;\n    _this._bloomEnabled = false;\n    _this._depthOfFieldEnabled = false;\n    _this._depthOfFieldBlurLevel = DepthOfFieldEffectBlurLevel.Low;\n    _this._fxaaEnabled = false;\n    _this._imageProcessingEnabled = true;\n    _this._bloomScale = 0.5;\n    _this._chromaticAberrationEnabled = false;\n    _this._grainEnabled = false;\n    _this._buildAllowed = true;\n    /**\r\n     * This is triggered each time the pipeline has been built.\r\n     */\n\n    _this.onBuildObservable = new Observable();\n    _this._resizeObserver = null;\n    _this._hardwareScaleLevel = 1.0;\n    _this._bloomKernel = 64;\n    /**\r\n     * Specifies the weight of the bloom in the final rendering\r\n     */\n\n    _this._bloomWeight = 0.15;\n    /**\r\n     * Specifies the luma threshold for the area that will be blurred by the bloom\r\n     */\n\n    _this._bloomThreshold = 0.9;\n    _this._samples = 1;\n    _this._hasCleared = false;\n    _this._prevPostProcess = null;\n    _this._prevPrevPostProcess = null;\n    _this._depthOfFieldSceneObserver = null;\n    _this._cameras = cameras || scene.cameras;\n    _this._cameras = _this._cameras.slice();\n    _this._camerasToBeAttached = _this._cameras.slice();\n    _this._buildAllowed = automaticBuild; // Initialize\n\n    _this._scene = scene;\n\n    var caps = _this._scene.getEngine().getCaps();\n\n    _this._hdr = hdr && (caps.textureHalfFloatRender || caps.textureFloatRender); // Misc\n\n    if (_this._hdr) {\n      if (caps.textureHalfFloatRender) {\n        _this._defaultPipelineTextureType = 2;\n      } else if (caps.textureFloatRender) {\n        _this._defaultPipelineTextureType = 1;\n      }\n    } else {\n      _this._defaultPipelineTextureType = 0;\n    } // Attach\n\n\n    scene.postProcessRenderPipelineManager.addPipeline(_this);\n\n    var engine = _this._scene.getEngine(); // Create post processes before hand so they can be modified before enabled.\n    // Block compilation flag is set to true to avoid compilation prior to use, these will be updated on first use in build pipeline.\n\n\n    _this.sharpen = new SharpenPostProcess(\"sharpen\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, _this._defaultPipelineTextureType, true);\n    _this._sharpenEffect = new PostProcessRenderEffect(engine, _this.SharpenPostProcessId, function () {\n      return _this.sharpen;\n    }, true);\n    _this.depthOfField = new DepthOfFieldEffect(_this._scene, null, _this._depthOfFieldBlurLevel, _this._defaultPipelineTextureType, true);\n    _this.bloom = new BloomEffect(_this._scene, _this._bloomScale, _this._bloomWeight, _this.bloomKernel, _this._defaultPipelineTextureType, true);\n    _this.chromaticAberration = new ChromaticAberrationPostProcess(\"ChromaticAberration\", engine.getRenderWidth(), engine.getRenderHeight(), 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, _this._defaultPipelineTextureType, true);\n    _this._chromaticAberrationEffect = new PostProcessRenderEffect(engine, _this.ChromaticAberrationPostProcessId, function () {\n      return _this.chromaticAberration;\n    }, true);\n    _this.grain = new GrainPostProcess(\"Grain\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, _this._defaultPipelineTextureType, true);\n    _this._grainEffect = new PostProcessRenderEffect(engine, _this.GrainPostProcessId, function () {\n      return _this.grain;\n    }, true);\n    _this._resizeObserver = engine.onResizeObservable.add(function () {\n      _this._hardwareScaleLevel = engine.getHardwareScalingLevel();\n      _this.bloomKernel = _this.bloomKernel;\n    });\n    _this._imageProcessingConfigurationObserver = _this._scene.imageProcessingConfiguration.onUpdateParameters.add(function () {\n      _this.bloom._downscale._exposure = _this._scene.imageProcessingConfiguration.exposure;\n\n      if (_this.imageProcessingEnabled !== _this._scene.imageProcessingConfiguration.isEnabled) {\n        _this._imageProcessingEnabled = _this._scene.imageProcessingConfiguration.isEnabled;\n\n        _this._buildPipeline();\n      }\n    });\n\n    _this._buildPipeline();\n\n    return _this;\n  }\n\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"scene\", {\n    /**\r\n     * Gets active scene\r\n     */\n    get: function get() {\n      return this._scene;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"sharpenEnabled\", {\n    get: function get() {\n      return this._sharpenEnabled;\n    },\n\n    /**\r\n     * Enable or disable the sharpen process from the pipeline\r\n     */\n    set: function set(enabled) {\n      if (this._sharpenEnabled === enabled) {\n        return;\n      }\n\n      this._sharpenEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"bloomKernel\", {\n    /**\r\n     * Specifies the size of the bloom blur kernel, relative to the final output size\r\n     */\n    get: function get() {\n      return this._bloomKernel;\n    },\n    set: function set(value) {\n      this._bloomKernel = value;\n      this.bloom.kernel = value / this._hardwareScaleLevel;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"bloomWeight\", {\n    get: function get() {\n      return this._bloomWeight;\n    },\n\n    /**\r\n     * The strength of the bloom.\r\n     */\n    set: function set(value) {\n      if (this._bloomWeight === value) {\n        return;\n      }\n\n      this.bloom.weight = value;\n      this._bloomWeight = value;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"bloomThreshold\", {\n    get: function get() {\n      return this._bloomThreshold;\n    },\n\n    /**\r\n     * The strength of the bloom.\r\n     */\n    set: function set(value) {\n      if (this._bloomThreshold === value) {\n        return;\n      }\n\n      this.bloom.threshold = value;\n      this._bloomThreshold = value;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"bloomScale\", {\n    get: function get() {\n      return this._bloomScale;\n    },\n\n    /**\r\n     * The scale of the bloom, lower value will provide better performance.\r\n     */\n    set: function set(value) {\n      if (this._bloomScale === value) {\n        return;\n      }\n\n      this._bloomScale = value; // recreate bloom and dispose old as this setting is not dynamic\n\n      this._rebuildBloom();\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"bloomEnabled\", {\n    get: function get() {\n      return this._bloomEnabled;\n    },\n\n    /**\r\n     * Enable or disable the bloom from the pipeline\r\n     */\n    set: function set(enabled) {\n      if (this._bloomEnabled === enabled) {\n        return;\n      }\n\n      this._bloomEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n\n  DefaultRenderingPipeline.prototype._rebuildBloom = function () {\n    // recreate bloom and dispose old as this setting is not dynamic\n    var oldBloom = this.bloom;\n    this.bloom = new BloomEffect(this._scene, this.bloomScale, this._bloomWeight, this.bloomKernel, this._defaultPipelineTextureType, false);\n    this.bloom.threshold = oldBloom.threshold;\n\n    for (var i = 0; i < this._cameras.length; i++) {\n      oldBloom.disposeEffects(this._cameras[i]);\n    }\n  };\n\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"depthOfFieldEnabled\", {\n    /**\r\n     * If the depth of field is enabled.\r\n     */\n    get: function get() {\n      return this._depthOfFieldEnabled;\n    },\n    set: function set(enabled) {\n      if (this._depthOfFieldEnabled === enabled) {\n        return;\n      }\n\n      this._depthOfFieldEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"depthOfFieldBlurLevel\", {\n    /**\r\n     * Blur level of the depth of field effect. (Higher blur will effect performance)\r\n     */\n    get: function get() {\n      return this._depthOfFieldBlurLevel;\n    },\n    set: function set(value) {\n      if (this._depthOfFieldBlurLevel === value) {\n        return;\n      }\n\n      this._depthOfFieldBlurLevel = value; // recreate dof and dispose old as this setting is not dynamic\n\n      var oldDof = this.depthOfField;\n      this.depthOfField = new DepthOfFieldEffect(this._scene, null, this._depthOfFieldBlurLevel, this._defaultPipelineTextureType, false);\n      this.depthOfField.focalLength = oldDof.focalLength;\n      this.depthOfField.focusDistance = oldDof.focusDistance;\n      this.depthOfField.fStop = oldDof.fStop;\n      this.depthOfField.lensSize = oldDof.lensSize;\n\n      for (var i = 0; i < this._cameras.length; i++) {\n        oldDof.disposeEffects(this._cameras[i]);\n      }\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"fxaaEnabled\", {\n    get: function get() {\n      return this._fxaaEnabled;\n    },\n\n    /**\r\n     * If the anti aliasing is enabled.\r\n     */\n    set: function set(enabled) {\n      if (this._fxaaEnabled === enabled) {\n        return;\n      }\n\n      this._fxaaEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"samples\", {\n    get: function get() {\n      return this._samples;\n    },\n\n    /**\r\n     * MSAA sample count, setting this to 4 will provide 4x anti aliasing. (default: 1)\r\n     */\n    set: function set(sampleCount) {\n      if (this._samples === sampleCount) {\n        return;\n      }\n\n      this._samples = sampleCount;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"imageProcessingEnabled\", {\n    get: function get() {\n      return this._imageProcessingEnabled;\n    },\n\n    /**\r\n     * If image processing is enabled.\r\n     */\n    set: function set(enabled) {\n      if (this._imageProcessingEnabled === enabled) {\n        return;\n      }\n\n      this._scene.imageProcessingConfiguration.isEnabled = enabled;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"glowLayerEnabled\", {\n    get: function get() {\n      return this._glowLayer != null;\n    },\n\n    /**\r\n     * If glow layer is enabled. (Adds a glow effect to emmissive materials)\r\n     */\n    set: function set(enabled) {\n      if (enabled && !this._glowLayer) {\n        this._glowLayer = new GlowLayer(\"\", this._scene);\n      } else if (!enabled && this._glowLayer) {\n        this._glowLayer.dispose();\n\n        this._glowLayer = null;\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"glowLayer\", {\n    /**\r\n     * Gets the glow layer (or null if not defined)\r\n     */\n    get: function get() {\n      return this._glowLayer;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"chromaticAberrationEnabled\", {\n    get: function get() {\n      return this._chromaticAberrationEnabled;\n    },\n\n    /**\r\n     * Enable or disable the chromaticAberration process from the pipeline\r\n     */\n    set: function set(enabled) {\n      if (this._chromaticAberrationEnabled === enabled) {\n        return;\n      }\n\n      this._chromaticAberrationEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(DefaultRenderingPipeline.prototype, \"grainEnabled\", {\n    get: function get() {\n      return this._grainEnabled;\n    },\n\n    /**\r\n     * Enable or disable the grain process from the pipeline\r\n     */\n    set: function set(enabled) {\n      if (this._grainEnabled === enabled) {\n        return;\n      }\n\n      this._grainEnabled = enabled;\n\n      this._buildPipeline();\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Get the class name\r\n   * @returns \"DefaultRenderingPipeline\"\r\n   */\n\n  DefaultRenderingPipeline.prototype.getClassName = function () {\n    return \"DefaultRenderingPipeline\";\n  };\n  /**\r\n   * Force the compilation of the entire pipeline.\r\n   */\n\n\n  DefaultRenderingPipeline.prototype.prepare = function () {\n    var previousState = this._buildAllowed;\n    this._buildAllowed = true;\n\n    this._buildPipeline();\n\n    this._buildAllowed = previousState;\n  };\n\n  DefaultRenderingPipeline.prototype._setAutoClearAndTextureSharing = function (postProcess, skipTextureSharing) {\n    if (skipTextureSharing === void 0) {\n      skipTextureSharing = false;\n    }\n\n    if (this._hasCleared) {\n      postProcess.autoClear = false;\n    } else {\n      postProcess.autoClear = true;\n      this._scene.autoClear = false;\n      this._hasCleared = true;\n    }\n\n    if (!skipTextureSharing) {\n      if (this._prevPrevPostProcess) {\n        postProcess.shareOutputWith(this._prevPrevPostProcess);\n      } else {\n        postProcess.useOwnOutput();\n      }\n\n      if (this._prevPostProcess) {\n        this._prevPrevPostProcess = this._prevPostProcess;\n      }\n\n      this._prevPostProcess = postProcess;\n    }\n  };\n\n  DefaultRenderingPipeline.prototype._buildPipeline = function () {\n    var _this = this;\n\n    if (!this._buildAllowed) {\n      return;\n    }\n\n    this._scene.autoClear = true;\n\n    var engine = this._scene.getEngine();\n\n    this._disposePostProcesses();\n\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras); // get back cameras to be used to reattach pipeline\n\n\n      this._cameras = this._camerasToBeAttached.slice();\n    }\n\n    this._reset();\n\n    this._prevPostProcess = null;\n    this._prevPrevPostProcess = null;\n    this._hasCleared = false;\n\n    if (this.depthOfFieldEnabled) {\n      // Multi camera suport\n      if (this._cameras.length > 1) {\n        for (var _i = 0, _a = this._cameras; _i < _a.length; _i++) {\n          var camera = _a[_i];\n\n          var depthRenderer = this._scene.enableDepthRenderer(camera);\n\n          depthRenderer.useOnlyInActiveCamera = true;\n        }\n\n        this._depthOfFieldSceneObserver = this._scene.onAfterRenderTargetsRenderObservable.add(function (scene) {\n          if (_this._cameras.indexOf(scene.activeCamera) > -1) {\n            _this.depthOfField.depthTexture = scene.enableDepthRenderer(scene.activeCamera).getDepthMap();\n          }\n        });\n      } else {\n        this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n\n        var depthRenderer = this._scene.enableDepthRenderer(this._cameras[0]);\n\n        this.depthOfField.depthTexture = depthRenderer.getDepthMap();\n      }\n\n      if (!this.depthOfField._isReady()) {\n        this.depthOfField._updateEffects();\n      }\n\n      this.addEffect(this.depthOfField);\n\n      this._setAutoClearAndTextureSharing(this.depthOfField._effects[0], true);\n    } else {\n      this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n    }\n\n    if (this.bloomEnabled) {\n      if (!this.bloom._isReady()) {\n        this.bloom._updateEffects();\n      }\n\n      this.addEffect(this.bloom);\n\n      this._setAutoClearAndTextureSharing(this.bloom._effects[0], true);\n    }\n\n    if (this._imageProcessingEnabled) {\n      this.imageProcessing = new ImageProcessingPostProcess(\"imageProcessing\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType);\n\n      if (this._hdr) {\n        this.addEffect(new PostProcessRenderEffect(engine, this.ImageProcessingPostProcessId, function () {\n          return _this.imageProcessing;\n        }, true));\n\n        this._setAutoClearAndTextureSharing(this.imageProcessing);\n      } else {\n        this._scene.imageProcessingConfiguration.applyByPostProcess = false;\n      }\n\n      if (!this.cameras || this.cameras.length === 0) {\n        this._scene.imageProcessingConfiguration.applyByPostProcess = false;\n      }\n\n      if (!this.imageProcessing.getEffect()) {\n        this.imageProcessing._updateParameters();\n      }\n    }\n\n    if (this.sharpenEnabled) {\n      if (!this.sharpen.isReady()) {\n        this.sharpen.updateEffect();\n      }\n\n      this.addEffect(this._sharpenEffect);\n\n      this._setAutoClearAndTextureSharing(this.sharpen);\n    }\n\n    if (this.grainEnabled) {\n      if (!this.grain.isReady()) {\n        this.grain.updateEffect();\n      }\n\n      this.addEffect(this._grainEffect);\n\n      this._setAutoClearAndTextureSharing(this.grain);\n    }\n\n    if (this.chromaticAberrationEnabled) {\n      if (!this.chromaticAberration.isReady()) {\n        this.chromaticAberration.updateEffect();\n      }\n\n      this.addEffect(this._chromaticAberrationEffect);\n\n      this._setAutoClearAndTextureSharing(this.chromaticAberration);\n    }\n\n    if (this.fxaaEnabled) {\n      this.fxaa = new FxaaPostProcess(\"fxaa\", 1.0, null, Texture.BILINEAR_SAMPLINGMODE, engine, false, this._defaultPipelineTextureType);\n      this.addEffect(new PostProcessRenderEffect(engine, this.FxaaPostProcessId, function () {\n        return _this.fxaa;\n      }, true));\n\n      this._setAutoClearAndTextureSharing(this.fxaa, true);\n    }\n\n    if (this._cameras !== null) {\n      this._scene.postProcessRenderPipelineManager.attachCamerasToRenderPipeline(this._name, this._cameras);\n    } // In multicamera mode, the scene needs to autoclear in between cameras.\n\n\n    if (this._scene.activeCameras && this._scene.activeCameras.length > 1) {\n      this._scene.autoClear = true;\n    }\n\n    if (!this._enableMSAAOnFirstPostProcess(this.samples) && this.samples > 1) {\n      Logger.Warn(\"MSAA failed to enable, MSAA is only supported in browsers that support webGL >= 2.0\");\n    }\n\n    this.onBuildObservable.notifyObservers(this);\n  };\n\n  DefaultRenderingPipeline.prototype._disposePostProcesses = function (disposeNonRecreated) {\n    if (disposeNonRecreated === void 0) {\n      disposeNonRecreated = false;\n    }\n\n    for (var i = 0; i < this._cameras.length; i++) {\n      var camera = this._cameras[i];\n\n      if (this.imageProcessing) {\n        this.imageProcessing.dispose(camera);\n      }\n\n      if (this.fxaa) {\n        this.fxaa.dispose(camera);\n      } // These are created in the constructor and should not be disposed on every pipeline change\n\n\n      if (disposeNonRecreated) {\n        if (this.sharpen) {\n          this.sharpen.dispose(camera);\n        }\n\n        if (this.depthOfField) {\n          this._scene.onAfterRenderTargetsRenderObservable.remove(this._depthOfFieldSceneObserver);\n\n          this.depthOfField.disposeEffects(camera);\n        }\n\n        if (this.bloom) {\n          this.bloom.disposeEffects(camera);\n        }\n\n        if (this.chromaticAberration) {\n          this.chromaticAberration.dispose(camera);\n        }\n\n        if (this.grain) {\n          this.grain.dispose(camera);\n        }\n\n        if (this._glowLayer) {\n          this._glowLayer.dispose();\n        }\n      }\n    }\n\n    this.imageProcessing = null;\n    this.fxaa = null;\n\n    if (disposeNonRecreated) {\n      this.sharpen = null;\n      this._sharpenEffect = null;\n      this.depthOfField = null;\n      this.bloom = null;\n      this.chromaticAberration = null;\n      this._chromaticAberrationEffect = null;\n      this.grain = null;\n      this._grainEffect = null;\n      this._glowLayer = null;\n    }\n  };\n  /**\r\n   * Adds a camera to the pipeline\r\n   * @param camera the camera to be added\r\n   */\n\n\n  DefaultRenderingPipeline.prototype.addCamera = function (camera) {\n    this._camerasToBeAttached.push(camera);\n\n    this._buildPipeline();\n  };\n  /**\r\n   * Removes a camera from the pipeline\r\n   * @param camera the camera to remove\r\n   */\n\n\n  DefaultRenderingPipeline.prototype.removeCamera = function (camera) {\n    var index = this._camerasToBeAttached.indexOf(camera);\n\n    this._camerasToBeAttached.splice(index, 1);\n\n    this._buildPipeline();\n  };\n  /**\r\n   * Dispose of the pipeline and stop all post processes\r\n   */\n\n\n  DefaultRenderingPipeline.prototype.dispose = function () {\n    this.onBuildObservable.clear();\n\n    this._disposePostProcesses(true);\n\n    this._scene.postProcessRenderPipelineManager.detachCamerasFromRenderPipeline(this._name, this._cameras);\n\n    this._scene.autoClear = true;\n\n    if (this._resizeObserver) {\n      this._scene.getEngine().onResizeObservable.remove(this._resizeObserver);\n\n      this._resizeObserver = null;\n    }\n\n    this._scene.imageProcessingConfiguration.onUpdateParameters.remove(this._imageProcessingConfigurationObserver);\n\n    _super.prototype.dispose.call(this);\n  };\n  /**\r\n   * Serialize the rendering pipeline (Used when exporting)\r\n   * @returns the serialized object\r\n   */\n\n\n  DefaultRenderingPipeline.prototype.serialize = function () {\n    var serializationObject = SerializationHelper.Serialize(this);\n    serializationObject.customType = \"DefaultRenderingPipeline\";\n    return serializationObject;\n  };\n  /**\r\n   * Parse the serialized pipeline\r\n   * @param source Source pipeline.\r\n   * @param scene The scene to load the pipeline to.\r\n   * @param rootUrl The URL of the serialized pipeline.\r\n   * @returns An instantiated pipeline from the serialized object.\r\n   */\n\n\n  DefaultRenderingPipeline.Parse = function (source, scene, rootUrl) {\n    return SerializationHelper.Parse(function () {\n      return new DefaultRenderingPipeline(source._name, source._name._hdr, scene);\n    }, source, scene, rootUrl);\n  };\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"sharpenEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomKernel\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"_bloomWeight\", void 0);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"_bloomThreshold\", void 0);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"_hdr\", void 0);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomWeight\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomThreshold\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomScale\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"bloomEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"depthOfFieldEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"depthOfFieldBlurLevel\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"fxaaEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"samples\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"imageProcessingEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"glowLayerEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"chromaticAberrationEnabled\", null);\n\n  __decorate([serialize()], DefaultRenderingPipeline.prototype, \"grainEnabled\", null);\n\n  return DefaultRenderingPipeline;\n}(PostProcessRenderPipeline);\n\nexport { DefaultRenderingPipeline };\n_TypeStore.RegisteredTypes[\"BABYLON.DefaultRenderingPipeline\"] = DefaultRenderingPipeline;","map":null,"metadata":{},"sourceType":"module"}