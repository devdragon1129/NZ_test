{"ast":null,"code":"import { Tools } from \"../Misc/tools\";\nimport { Observable } from \"../Misc/observable\";\nimport { Vector3, TmpVectors } from \"../Maths/math.vector\";\nimport { Engine } from \"../Engines/engine\";\nimport { Logger } from \"../Misc/logger\";\nimport { _DevTools } from \"../Misc/devTools\";\n/**\r\n * Defines a sound that can be played in the application.\r\n * The sound can either be an ambient track or a simple sound played in reaction to a user action.\r\n * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music\r\n */\n\nvar Sound =\n/** @class */\nfunction () {\n  /**\r\n   * Create a sound and attach it to a scene\r\n   * @param name Name of your sound\r\n   * @param urlOrArrayBuffer Url to the sound to load async or ArrayBuffer, it also works with MediaStreams\r\n   * @param scene defines the scene the sound belongs to\r\n   * @param readyToPlayCallback Provide a callback function if you'd like to load your code once the sound is ready to be played\r\n   * @param options Objects to provide with the current available options: autoplay, loop, volume, spatialSound, maxDistance, rolloffFactor, refDistance, distanceModel, panningModel, streaming\r\n   */\n  function Sound(name, urlOrArrayBuffer, scene, readyToPlayCallback, options) {\n    var _this = this;\n\n    if (readyToPlayCallback === void 0) {\n      readyToPlayCallback = null;\n    }\n\n    var _a, _b, _c, _d;\n    /**\r\n     * Does the sound autoplay once loaded.\r\n     */\n\n\n    this.autoplay = false;\n    /**\r\n     * Does the sound loop after it finishes playing once.\r\n     */\n\n    this.loop = false;\n    /**\r\n     * Does the sound use a custom attenuation curve to simulate the falloff\r\n     * happening when the source gets further away from the camera.\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-your-own-custom-attenuation-function\r\n     */\n\n    this.useCustomAttenuation = false;\n    /**\r\n     * Is this sound currently played.\r\n     */\n\n    this.isPlaying = false;\n    /**\r\n     * Is this sound currently paused.\r\n     */\n\n    this.isPaused = false;\n    /**\r\n     * Does this sound enables spatial sound.\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n     */\n\n    this.spatialSound = false;\n    /**\r\n     * Define the reference distance the sound should be heard perfectly.\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n     */\n\n    this.refDistance = 1;\n    /**\r\n     * Define the roll off factor of spatial sounds.\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n     */\n\n    this.rolloffFactor = 1;\n    /**\r\n     * Define the max distance the sound should be heard (intensity just became 0 at this point).\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n     */\n\n    this.maxDistance = 100;\n    /**\r\n     * Define the distance attenuation model the sound will follow.\r\n     * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n     */\n\n    this.distanceModel = \"linear\";\n    /**\r\n     * Gets or sets an object used to store user defined information for the sound.\r\n     */\n\n    this.metadata = null;\n    /**\r\n     * Observable event when the current playing sound finishes.\r\n     */\n\n    this.onEndedObservable = new Observable();\n    this._panningModel = \"equalpower\";\n    this._playbackRate = 1;\n    this._streaming = false;\n    this._startTime = 0;\n    this._startOffset = 0;\n    this._position = Vector3.Zero();\n    /** @hidden */\n\n    this._positionInEmitterSpace = false;\n    this._localDirection = new Vector3(1, 0, 0);\n    this._volume = 1;\n    this._isReadyToPlay = false;\n    this._isDirectional = false; // Used if you'd like to create a directional sound.\n    // If not set, the sound will be omnidirectional\n\n    this._coneInnerAngle = 360;\n    this._coneOuterAngle = 360;\n    this._coneOuterGain = 0;\n    this._isOutputConnected = false;\n    this._urlType = \"Unknown\";\n    this.name = name;\n    this._scene = scene;\n\n    Sound._SceneComponentInitialization(scene);\n\n    this._readyToPlayCallback = readyToPlayCallback; // Default custom attenuation function is a linear attenuation\n\n    this._customAttenuationFunction = function (currentVolume, currentDistance, maxDistance, refDistance, rolloffFactor) {\n      if (currentDistance < maxDistance) {\n        return currentVolume * (1 - currentDistance / maxDistance);\n      } else {\n        return 0;\n      }\n    };\n\n    if (options) {\n      this.autoplay = options.autoplay || false;\n      this.loop = options.loop || false; // if volume === 0, we need another way to check this option\n\n      if (options.volume !== undefined) {\n        this._volume = options.volume;\n      }\n\n      this.spatialSound = (_a = options.spatialSound) !== null && _a !== void 0 ? _a : false;\n      this.maxDistance = (_b = options.maxDistance) !== null && _b !== void 0 ? _b : 100;\n      this.useCustomAttenuation = (_c = options.useCustomAttenuation) !== null && _c !== void 0 ? _c : false;\n      this.rolloffFactor = options.rolloffFactor || 1;\n      this.refDistance = options.refDistance || 1;\n      this.distanceModel = options.distanceModel || \"linear\";\n      this._playbackRate = options.playbackRate || 1;\n      this._streaming = (_d = options.streaming) !== null && _d !== void 0 ? _d : false;\n      this._length = options.length;\n      this._offset = options.offset;\n    }\n\n    if (Engine.audioEngine.canUseWebAudio && Engine.audioEngine.audioContext) {\n      this._soundGain = Engine.audioEngine.audioContext.createGain();\n      this._soundGain.gain.value = this._volume;\n      this._inputAudioNode = this._soundGain;\n      this._outputAudioNode = this._soundGain;\n\n      if (this.spatialSound) {\n        this._createSpatialParameters();\n      }\n\n      this._scene.mainSoundTrack.addSound(this);\n\n      var validParameter = true; // if no parameter is passed, you need to call setAudioBuffer yourself to prepare the sound\n\n      if (urlOrArrayBuffer) {\n        try {\n          if (typeof urlOrArrayBuffer === \"string\") {\n            this._urlType = \"String\";\n          } else if (urlOrArrayBuffer instanceof ArrayBuffer) {\n            this._urlType = \"ArrayBuffer\";\n          } else if (urlOrArrayBuffer instanceof MediaStream) {\n            this._urlType = \"MediaStream\";\n          } else if (Array.isArray(urlOrArrayBuffer)) {\n            this._urlType = \"Array\";\n          }\n\n          var urls = [];\n          var codecSupportedFound = false;\n\n          switch (this._urlType) {\n            case \"MediaStream\":\n              this._streaming = true;\n              this._isReadyToPlay = true;\n              this._streamingSource = Engine.audioEngine.audioContext.createMediaStreamSource(urlOrArrayBuffer);\n\n              if (this.autoplay) {\n                this.play(0, this._offset, this._length);\n              }\n\n              if (this._readyToPlayCallback) {\n                this._readyToPlayCallback();\n              }\n\n              break;\n\n            case \"ArrayBuffer\":\n              if (urlOrArrayBuffer.byteLength > 0) {\n                codecSupportedFound = true;\n\n                this._soundLoaded(urlOrArrayBuffer);\n              }\n\n              break;\n\n            case \"String\":\n              urls.push(urlOrArrayBuffer);\n\n            case \"Array\":\n              if (urls.length === 0) {\n                urls = urlOrArrayBuffer;\n              } // If we found a supported format, we load it immediately and stop the loop\n\n\n              for (var i = 0; i < urls.length; i++) {\n                var url = urls[i];\n                codecSupportedFound = options && options.skipCodecCheck || url.indexOf(\".mp3\", url.length - 4) !== -1 && Engine.audioEngine.isMP3supported || url.indexOf(\".ogg\", url.length - 4) !== -1 && Engine.audioEngine.isOGGsupported || url.indexOf(\".wav\", url.length - 4) !== -1 || url.indexOf(\".m4a\", url.length - 4) !== -1 || url.indexOf(\"blob:\") !== -1;\n\n                if (codecSupportedFound) {\n                  // Loading sound using XHR2\n                  if (!this._streaming) {\n                    this._scene._loadFile(url, function (data) {\n                      _this._soundLoaded(data);\n                    }, undefined, true, true, function (exception) {\n                      if (exception) {\n                        Logger.Error(\"XHR \" + exception.status + \" error on: \" + url + \".\");\n                      }\n\n                      Logger.Error(\"Sound creation aborted.\");\n\n                      _this._scene.mainSoundTrack.removeSound(_this);\n                    });\n                  } // Streaming sound using HTML5 Audio tag\n                  else {\n                    this._htmlAudioElement = new Audio(url);\n                    this._htmlAudioElement.controls = false;\n                    this._htmlAudioElement.loop = this.loop;\n                    Tools.SetCorsBehavior(url, this._htmlAudioElement);\n                    this._htmlAudioElement.preload = \"auto\";\n\n                    this._htmlAudioElement.addEventListener(\"canplaythrough\", function () {\n                      _this._isReadyToPlay = true;\n\n                      if (_this.autoplay) {\n                        _this.play(0, _this._offset, _this._length);\n                      }\n\n                      if (_this._readyToPlayCallback) {\n                        _this._readyToPlayCallback();\n                      }\n                    });\n\n                    document.body.appendChild(this._htmlAudioElement);\n\n                    this._htmlAudioElement.load();\n                  }\n\n                  break;\n                }\n              }\n\n              break;\n\n            default:\n              validParameter = false;\n              break;\n          }\n\n          if (!validParameter) {\n            Logger.Error(\"Parameter must be a URL to the sound, an Array of URLs (.mp3 & .ogg) or an ArrayBuffer of the sound.\");\n          } else {\n            if (!codecSupportedFound) {\n              this._isReadyToPlay = true; // Simulating a ready to play event to avoid breaking code path\n\n              if (this._readyToPlayCallback) {\n                window.setTimeout(function () {\n                  if (_this._readyToPlayCallback) {\n                    _this._readyToPlayCallback();\n                  }\n                }, 1000);\n              }\n            }\n          }\n        } catch (ex) {\n          Logger.Error(\"Unexpected error. Sound creation aborted.\");\n\n          this._scene.mainSoundTrack.removeSound(this);\n        }\n      }\n    } else {\n      // Adding an empty sound to avoid breaking audio calls for non Web Audio browsers\n      this._scene.mainSoundTrack.addSound(this);\n\n      if (!Engine.audioEngine.WarnedWebAudioUnsupported) {\n        Logger.Error(\"Web Audio is not supported by your browser.\");\n        Engine.audioEngine.WarnedWebAudioUnsupported = true;\n      } // Simulating a ready to play event to avoid breaking code for non web audio browsers\n\n\n      if (this._readyToPlayCallback) {\n        window.setTimeout(function () {\n          if (_this._readyToPlayCallback) {\n            _this._readyToPlayCallback();\n          }\n        }, 1000);\n      }\n    }\n  }\n\n  Object.defineProperty(Sound.prototype, \"currentTime\", {\n    /**\r\n     * Gets the current time for the sound.\r\n     */\n    get: function get() {\n      if (this._htmlAudioElement) {\n        return this._htmlAudioElement.currentTime;\n      }\n\n      var currentTime = this._startOffset;\n\n      if (this.isPlaying && Engine.audioEngine.audioContext) {\n        currentTime += Engine.audioEngine.audioContext.currentTime - this._startTime;\n      }\n\n      return currentTime;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Release the sound and its associated resources\r\n   */\n\n  Sound.prototype.dispose = function () {\n    if (Engine.audioEngine.canUseWebAudio) {\n      if (this.isPlaying) {\n        this.stop();\n      }\n\n      this._isReadyToPlay = false;\n\n      if (this.soundTrackId === -1) {\n        this._scene.mainSoundTrack.removeSound(this);\n      } else if (this._scene.soundTracks) {\n        this._scene.soundTracks[this.soundTrackId].removeSound(this);\n      }\n\n      if (this._soundGain) {\n        this._soundGain.disconnect();\n\n        this._soundGain = null;\n      }\n\n      if (this._soundPanner) {\n        this._soundPanner.disconnect();\n\n        this._soundPanner = null;\n      }\n\n      if (this._soundSource) {\n        this._soundSource.disconnect();\n\n        this._soundSource = null;\n      }\n\n      this._audioBuffer = null;\n\n      if (this._htmlAudioElement) {\n        this._htmlAudioElement.pause();\n\n        this._htmlAudioElement.src = \"\";\n        document.body.removeChild(this._htmlAudioElement);\n      }\n\n      if (this._streamingSource) {\n        this._streamingSource.disconnect();\n      }\n\n      if (this._connectedTransformNode && this._registerFunc) {\n        this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n\n        this._connectedTransformNode = null;\n      }\n    }\n  };\n  /**\r\n   * Gets if the sounds is ready to be played or not.\r\n   * @returns true if ready, otherwise false\r\n   */\n\n\n  Sound.prototype.isReady = function () {\n    return this._isReadyToPlay;\n  };\n\n  Sound.prototype._soundLoaded = function (audioData) {\n    var _this = this;\n\n    if (!Engine.audioEngine.audioContext) {\n      return;\n    }\n\n    Engine.audioEngine.audioContext.decodeAudioData(audioData, function (buffer) {\n      _this._audioBuffer = buffer;\n      _this._isReadyToPlay = true;\n\n      if (_this.autoplay) {\n        _this.play(0, _this._offset, _this._length);\n      }\n\n      if (_this._readyToPlayCallback) {\n        _this._readyToPlayCallback();\n      }\n    }, function (err) {\n      Logger.Error(\"Error while decoding audio data for: \" + _this.name + \" / Error: \" + err);\n    });\n  };\n  /**\r\n   * Sets the data of the sound from an audiobuffer\r\n   * @param audioBuffer The audioBuffer containing the data\r\n   */\n\n\n  Sound.prototype.setAudioBuffer = function (audioBuffer) {\n    if (Engine.audioEngine.canUseWebAudio) {\n      this._audioBuffer = audioBuffer;\n      this._isReadyToPlay = true;\n    }\n  };\n  /**\r\n   * Updates the current sounds options such as maxdistance, loop...\r\n   * @param options A JSON object containing values named as the object properties\r\n   */\n\n\n  Sound.prototype.updateOptions = function (options) {\n    var _a, _b, _c, _d, _e, _f, _g, _h, _j;\n\n    if (options) {\n      this.loop = (_a = options.loop) !== null && _a !== void 0 ? _a : this.loop;\n      this.maxDistance = (_b = options.maxDistance) !== null && _b !== void 0 ? _b : this.maxDistance;\n      this.useCustomAttenuation = (_c = options.useCustomAttenuation) !== null && _c !== void 0 ? _c : this.useCustomAttenuation;\n      this.rolloffFactor = (_d = options.rolloffFactor) !== null && _d !== void 0 ? _d : this.rolloffFactor;\n      this.refDistance = (_e = options.refDistance) !== null && _e !== void 0 ? _e : this.refDistance;\n      this.distanceModel = (_f = options.distanceModel) !== null && _f !== void 0 ? _f : this.distanceModel;\n      this._playbackRate = (_g = options.playbackRate) !== null && _g !== void 0 ? _g : this._playbackRate;\n      this._length = (_h = options.length) !== null && _h !== void 0 ? _h : undefined;\n      this._offset = (_j = options.offset) !== null && _j !== void 0 ? _j : undefined;\n\n      this._updateSpatialParameters();\n\n      if (this.isPlaying) {\n        if (this._streaming && this._htmlAudioElement) {\n          this._htmlAudioElement.playbackRate = this._playbackRate;\n\n          if (this._htmlAudioElement.loop !== this.loop) {\n            this._htmlAudioElement.loop = this.loop;\n          }\n        } else {\n          if (this._soundSource) {\n            this._soundSource.playbackRate.value = this._playbackRate;\n\n            if (this._soundSource.loop !== this.loop) {\n              this._soundSource.loop = this.loop;\n            }\n\n            if (this._offset !== undefined && this._soundSource.loopStart !== this._offset) {\n              this._soundSource.loopStart = this._offset;\n            }\n\n            if (this._length !== undefined && this._length !== this._soundSource.loopEnd) {\n              this._soundSource.loopEnd = (this._offset | 0) + this._length;\n            }\n          }\n        }\n      }\n    }\n  };\n\n  Sound.prototype._createSpatialParameters = function () {\n    if (Engine.audioEngine.canUseWebAudio && Engine.audioEngine.audioContext) {\n      if (this._scene.headphone) {\n        this._panningModel = \"HRTF\";\n      }\n\n      this._soundPanner = Engine.audioEngine.audioContext.createPanner();\n\n      if (this._soundPanner && this._outputAudioNode) {\n        this._updateSpatialParameters();\n\n        this._soundPanner.connect(this._outputAudioNode);\n\n        this._inputAudioNode = this._soundPanner;\n      }\n    }\n  };\n\n  Sound.prototype._updateSpatialParameters = function () {\n    if (this.spatialSound && this._soundPanner) {\n      if (this.useCustomAttenuation) {\n        // Tricks to disable in a way embedded Web Audio attenuation\n        this._soundPanner.distanceModel = \"linear\";\n        this._soundPanner.maxDistance = Number.MAX_VALUE;\n        this._soundPanner.refDistance = 1;\n        this._soundPanner.rolloffFactor = 1;\n        this._soundPanner.panningModel = this._panningModel;\n      } else {\n        this._soundPanner.distanceModel = this.distanceModel;\n        this._soundPanner.maxDistance = this.maxDistance;\n        this._soundPanner.refDistance = this.refDistance;\n        this._soundPanner.rolloffFactor = this.rolloffFactor;\n        this._soundPanner.panningModel = this._panningModel;\n      }\n    }\n  };\n  /**\r\n   * Switch the panning model to HRTF:\r\n   * Renders a stereo output of higher quality than equalpower — it uses a convolution with measured impulse responses from human subjects.\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n   */\n\n\n  Sound.prototype.switchPanningModelToHRTF = function () {\n    this._panningModel = \"HRTF\";\n\n    this._switchPanningModel();\n  };\n  /**\r\n   * Switch the panning model to Equal Power:\r\n   * Represents the equal-power panning algorithm, generally regarded as simple and efficient. equalpower is the default value.\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-a-spatial-3d-sound\r\n   */\n\n\n  Sound.prototype.switchPanningModelToEqualPower = function () {\n    this._panningModel = \"equalpower\";\n\n    this._switchPanningModel();\n  };\n\n  Sound.prototype._switchPanningModel = function () {\n    if (Engine.audioEngine.canUseWebAudio && this.spatialSound && this._soundPanner) {\n      this._soundPanner.panningModel = this._panningModel;\n    }\n  };\n  /**\r\n   * Connect this sound to a sound track audio node like gain...\r\n   * @param soundTrackAudioNode the sound track audio node to connect to\r\n   */\n\n\n  Sound.prototype.connectToSoundTrackAudioNode = function (soundTrackAudioNode) {\n    if (Engine.audioEngine.canUseWebAudio && this._outputAudioNode) {\n      if (this._isOutputConnected) {\n        this._outputAudioNode.disconnect();\n      }\n\n      this._outputAudioNode.connect(soundTrackAudioNode);\n\n      this._isOutputConnected = true;\n    }\n  };\n  /**\r\n   * Transform this sound into a directional source\r\n   * @param coneInnerAngle Size of the inner cone in degree\r\n   * @param coneOuterAngle Size of the outer cone in degree\r\n   * @param coneOuterGain Volume of the sound outside the outer cone (between 0.0 and 1.0)\r\n   */\n\n\n  Sound.prototype.setDirectionalCone = function (coneInnerAngle, coneOuterAngle, coneOuterGain) {\n    if (coneOuterAngle < coneInnerAngle) {\n      Logger.Error(\"setDirectionalCone(): outer angle of the cone must be superior or equal to the inner angle.\");\n      return;\n    }\n\n    this._coneInnerAngle = coneInnerAngle;\n    this._coneOuterAngle = coneOuterAngle;\n    this._coneOuterGain = coneOuterGain;\n    this._isDirectional = true;\n\n    if (this.isPlaying && this.loop) {\n      this.stop();\n      this.play(0, this._offset, this._length);\n    }\n  };\n\n  Object.defineProperty(Sound.prototype, \"directionalConeInnerAngle\", {\n    /**\r\n     * Gets or sets the inner angle for the directional cone.\r\n     */\n    get: function get() {\n      return this._coneInnerAngle;\n    },\n\n    /**\r\n     * Gets or sets the inner angle for the directional cone.\r\n     */\n    set: function set(value) {\n      if (value != this._coneInnerAngle) {\n        if (this._coneOuterAngle < value) {\n          Logger.Error(\"directionalConeInnerAngle: outer angle of the cone must be superior or equal to the inner angle.\");\n          return;\n        }\n\n        this._coneInnerAngle = value;\n\n        if (Engine.audioEngine.canUseWebAudio && this.spatialSound && this._soundPanner) {\n          this._soundPanner.coneInnerAngle = this._coneInnerAngle;\n        }\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  Object.defineProperty(Sound.prototype, \"directionalConeOuterAngle\", {\n    /**\r\n     * Gets or sets the outer angle for the directional cone.\r\n     */\n    get: function get() {\n      return this._coneOuterAngle;\n    },\n\n    /**\r\n     * Gets or sets the outer angle for the directional cone.\r\n     */\n    set: function set(value) {\n      if (value != this._coneOuterAngle) {\n        if (value < this._coneInnerAngle) {\n          Logger.Error(\"directionalConeOuterAngle: outer angle of the cone must be superior or equal to the inner angle.\");\n          return;\n        }\n\n        this._coneOuterAngle = value;\n\n        if (Engine.audioEngine.canUseWebAudio && this.spatialSound && this._soundPanner) {\n          this._soundPanner.coneOuterAngle = this._coneOuterAngle;\n        }\n      }\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Sets the position of the emitter if spatial sound is enabled\r\n   * @param newPosition Defines the new posisiton\r\n   */\n\n  Sound.prototype.setPosition = function (newPosition) {\n    this._position = newPosition;\n\n    if (Engine.audioEngine.canUseWebAudio && this.spatialSound && this._soundPanner && !isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {\n      this._soundPanner.setPosition(this._position.x, this._position.y, this._position.z);\n    }\n  };\n  /**\r\n   * Sets the local direction of the emitter if spatial sound is enabled\r\n   * @param newLocalDirection Defines the new local direction\r\n   */\n\n\n  Sound.prototype.setLocalDirectionToMesh = function (newLocalDirection) {\n    this._localDirection = newLocalDirection;\n\n    if (Engine.audioEngine.canUseWebAudio && this._connectedTransformNode && this.isPlaying) {\n      this._updateDirection();\n    }\n  };\n\n  Sound.prototype._updateDirection = function () {\n    if (!this._connectedTransformNode || !this._soundPanner) {\n      return;\n    }\n\n    var mat = this._connectedTransformNode.getWorldMatrix();\n\n    var direction = Vector3.TransformNormal(this._localDirection, mat);\n    direction.normalize();\n\n    this._soundPanner.setOrientation(direction.x, direction.y, direction.z);\n  };\n  /** @hidden */\n\n\n  Sound.prototype.updateDistanceFromListener = function () {\n    if (Engine.audioEngine.canUseWebAudio && this._connectedTransformNode && this.useCustomAttenuation && this._soundGain && this._scene.activeCamera) {\n      var distance = this._connectedTransformNode.getDistanceToCamera(this._scene.activeCamera);\n\n      this._soundGain.gain.value = this._customAttenuationFunction(this._volume, distance, this.maxDistance, this.refDistance, this.rolloffFactor);\n    }\n  };\n  /**\r\n   * Sets a new custom attenuation function for the sound.\r\n   * @param callback Defines the function used for the attenuation\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#creating-your-own-custom-attenuation-function\r\n   */\n\n\n  Sound.prototype.setAttenuationFunction = function (callback) {\n    this._customAttenuationFunction = callback;\n  };\n  /**\r\n   * Play the sound\r\n   * @param time (optional) Start the sound after X seconds. Start immediately (0) by default.\r\n   * @param offset (optional) Start the sound at a specific time in seconds\r\n   * @param length (optional) Sound duration (in seconds)\r\n   */\n\n\n  Sound.prototype.play = function (time, offset, length) {\n    var _this = this;\n\n    if (this._isReadyToPlay && this._scene.audioEnabled && Engine.audioEngine.audioContext) {\n      try {\n        if (this._startOffset < 0) {\n          time = -this._startOffset;\n          this._startOffset = 0;\n        }\n\n        var startTime = time ? Engine.audioEngine.audioContext.currentTime + time : Engine.audioEngine.audioContext.currentTime;\n\n        if (!this._soundSource || !this._streamingSource) {\n          if (this.spatialSound && this._soundPanner) {\n            if (!isNaN(this._position.x) && !isNaN(this._position.y) && !isNaN(this._position.z)) {\n              this._soundPanner.setPosition(this._position.x, this._position.y, this._position.z);\n            }\n\n            if (this._isDirectional) {\n              this._soundPanner.coneInnerAngle = this._coneInnerAngle;\n              this._soundPanner.coneOuterAngle = this._coneOuterAngle;\n              this._soundPanner.coneOuterGain = this._coneOuterGain;\n\n              if (this._connectedTransformNode) {\n                this._updateDirection();\n              } else {\n                this._soundPanner.setOrientation(this._localDirection.x, this._localDirection.y, this._localDirection.z);\n              }\n            }\n          }\n        }\n\n        if (this._streaming) {\n          if (!this._streamingSource) {\n            this._streamingSource = Engine.audioEngine.audioContext.createMediaElementSource(this._htmlAudioElement);\n\n            this._htmlAudioElement.onended = function () {\n              _this._onended();\n            };\n\n            this._htmlAudioElement.playbackRate = this._playbackRate;\n          }\n\n          this._streamingSource.disconnect();\n\n          if (this._inputAudioNode) {\n            this._streamingSource.connect(this._inputAudioNode);\n          }\n\n          if (this._htmlAudioElement) {\n            // required to manage properly the new suspended default state of Chrome\n            // When the option 'streaming: true' is used, we need first to wait for\n            // the audio engine to be unlocked by a user gesture before trying to play\n            // an HTML Audio elememt\n            var _tryToPlay = function tryToPlay() {\n              if (Engine.audioEngine.unlocked) {\n                var playPromise = _this._htmlAudioElement.play(); // In browsers that don’t yet support this functionality,\n                // playPromise won’t be defined.\n\n\n                if (playPromise !== undefined) {\n                  playPromise.catch(function (error) {\n                    // Automatic playback failed.\n                    // Waiting for the audio engine to be unlocked by user click on unmute\n                    Engine.audioEngine.lock();\n\n                    if (_this.loop || _this.autoplay) {\n                      Engine.audioEngine.onAudioUnlockedObservable.addOnce(function () {\n                        _tryToPlay();\n                      });\n                    }\n                  });\n                }\n              } else {\n                if (_this.loop || _this.autoplay) {\n                  Engine.audioEngine.onAudioUnlockedObservable.addOnce(function () {\n                    _tryToPlay();\n                  });\n                }\n              }\n            };\n\n            _tryToPlay();\n          }\n        } else {\n          var _tryToPlay = function _tryToPlay() {\n            if (Engine.audioEngine.audioContext) {\n              length = length || _this._length;\n              offset = offset || _this._offset;\n\n              if (_this._soundSource) {\n                var oldSource_1 = _this._soundSource;\n\n                oldSource_1.onended = function () {\n                  oldSource_1.disconnect();\n                };\n              }\n\n              _this._soundSource = Engine.audioEngine.audioContext.createBufferSource();\n\n              if (_this._soundSource && _this._inputAudioNode) {\n                _this._soundSource.buffer = _this._audioBuffer;\n\n                _this._soundSource.connect(_this._inputAudioNode);\n\n                _this._soundSource.loop = _this.loop;\n\n                if (offset !== undefined) {\n                  _this._soundSource.loopStart = offset;\n                }\n\n                if (length !== undefined) {\n                  _this._soundSource.loopEnd = (offset | 0) + length;\n                }\n\n                _this._soundSource.playbackRate.value = _this._playbackRate;\n\n                _this._soundSource.onended = function () {\n                  _this._onended();\n                };\n\n                startTime = time ? Engine.audioEngine.audioContext.currentTime + time : Engine.audioEngine.audioContext.currentTime;\n                var actualOffset = _this.isPaused ? _this._startOffset % _this._soundSource.buffer.duration : offset ? offset : 0;\n\n                _this._soundSource.start(startTime, actualOffset, _this.loop ? undefined : length);\n              }\n            }\n          };\n\n          if (Engine.audioEngine.audioContext.state === \"suspended\") {\n            // Wait a bit for FF as context seems late to be ready.\n            setTimeout(function () {\n              if (Engine.audioEngine.audioContext.state === \"suspended\") {\n                // Automatic playback failed.\n                // Waiting for the audio engine to be unlocked by user click on unmute\n                Engine.audioEngine.lock();\n\n                if (_this.loop || _this.autoplay) {\n                  Engine.audioEngine.onAudioUnlockedObservable.addOnce(function () {\n                    _tryToPlay();\n                  });\n                }\n              } else {\n                _tryToPlay();\n              }\n            }, 500);\n          } else {\n            _tryToPlay();\n          }\n        }\n\n        this._startTime = startTime;\n        this.isPlaying = true;\n        this.isPaused = false;\n      } catch (ex) {\n        Logger.Error(\"Error while trying to play audio: \" + this.name + \", \" + ex.message);\n      }\n    }\n  };\n\n  Sound.prototype._onended = function () {\n    this.isPlaying = false;\n    this._startOffset = 0;\n\n    if (this.onended) {\n      this.onended();\n    }\n\n    this.onEndedObservable.notifyObservers(this);\n  };\n  /**\r\n   * Stop the sound\r\n   * @param time (optional) Stop the sound after X seconds. Stop immediately (0) by default.\r\n   */\n\n\n  Sound.prototype.stop = function (time) {\n    var _this = this;\n\n    if (this.isPlaying) {\n      if (this._streaming) {\n        if (this._htmlAudioElement) {\n          this._htmlAudioElement.pause(); // Test needed for Firefox or it will generate an Invalid State Error\n\n\n          if (this._htmlAudioElement.currentTime > 0) {\n            this._htmlAudioElement.currentTime = 0;\n          }\n        } else {\n          this._streamingSource.disconnect();\n        }\n\n        this.isPlaying = false;\n      } else if (Engine.audioEngine.audioContext && this._soundSource) {\n        var stopTime = time ? Engine.audioEngine.audioContext.currentTime + time : Engine.audioEngine.audioContext.currentTime;\n\n        this._soundSource.stop(stopTime);\n\n        this._soundSource.onended = function () {\n          _this.isPlaying = false;\n        };\n\n        if (!this.isPaused) {\n          this._startOffset = 0;\n        }\n      }\n    }\n  };\n  /**\r\n   * Put the sound in pause\r\n   */\n\n\n  Sound.prototype.pause = function () {\n    if (this.isPlaying) {\n      this.isPaused = true;\n\n      if (this._streaming) {\n        if (this._htmlAudioElement) {\n          this._htmlAudioElement.pause();\n        } else {\n          this._streamingSource.disconnect();\n        }\n      } else if (Engine.audioEngine.audioContext) {\n        this.stop(0);\n        this._startOffset += Engine.audioEngine.audioContext.currentTime - this._startTime;\n      }\n    }\n  };\n  /**\r\n   * Sets a dedicated volume for this sounds\r\n   * @param newVolume Define the new volume of the sound\r\n   * @param time Define time for gradual change to new volume\r\n   */\n\n\n  Sound.prototype.setVolume = function (newVolume, time) {\n    if (Engine.audioEngine.canUseWebAudio && this._soundGain) {\n      if (time && Engine.audioEngine.audioContext) {\n        this._soundGain.gain.cancelScheduledValues(Engine.audioEngine.audioContext.currentTime);\n\n        this._soundGain.gain.setValueAtTime(this._soundGain.gain.value, Engine.audioEngine.audioContext.currentTime);\n\n        this._soundGain.gain.linearRampToValueAtTime(newVolume, Engine.audioEngine.audioContext.currentTime + time);\n      } else {\n        this._soundGain.gain.value = newVolume;\n      }\n    }\n\n    this._volume = newVolume;\n  };\n  /**\r\n   * Set the sound play back rate\r\n   * @param newPlaybackRate Define the playback rate the sound should be played at\r\n   */\n\n\n  Sound.prototype.setPlaybackRate = function (newPlaybackRate) {\n    this._playbackRate = newPlaybackRate;\n\n    if (this.isPlaying) {\n      if (this._streaming && this._htmlAudioElement) {\n        this._htmlAudioElement.playbackRate = this._playbackRate;\n      } else if (this._soundSource) {\n        this._soundSource.playbackRate.value = this._playbackRate;\n      }\n    }\n  };\n  /**\r\n   * Gets the volume of the sound.\r\n   * @returns the volume of the sound\r\n   */\n\n\n  Sound.prototype.getVolume = function () {\n    return this._volume;\n  };\n  /**\r\n   * Attach the sound to a dedicated mesh\r\n   * @param transformNode The transform node to connect the sound with\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#attaching-a-sound-to-a-mesh\r\n   */\n\n\n  Sound.prototype.attachToMesh = function (transformNode) {\n    var _this = this;\n\n    if (this._connectedTransformNode && this._registerFunc) {\n      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n\n      this._registerFunc = null;\n    }\n\n    this._connectedTransformNode = transformNode;\n\n    if (!this.spatialSound) {\n      this.spatialSound = true;\n\n      this._createSpatialParameters();\n\n      if (this.isPlaying && this.loop) {\n        this.stop();\n        this.play(0, this._offset, this._length);\n      }\n    }\n\n    this._onRegisterAfterWorldMatrixUpdate(this._connectedTransformNode);\n\n    this._registerFunc = function (transformNode) {\n      return _this._onRegisterAfterWorldMatrixUpdate(transformNode);\n    };\n\n    this._connectedTransformNode.registerAfterWorldMatrixUpdate(this._registerFunc);\n  };\n  /**\r\n   * Detach the sound from the previously attached mesh\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#attaching-a-sound-to-a-mesh\r\n   */\n\n\n  Sound.prototype.detachFromMesh = function () {\n    if (this._connectedTransformNode && this._registerFunc) {\n      this._connectedTransformNode.unregisterAfterWorldMatrixUpdate(this._registerFunc);\n\n      this._registerFunc = null;\n      this._connectedTransformNode = null;\n    }\n  };\n\n  Sound.prototype._onRegisterAfterWorldMatrixUpdate = function (node) {\n    if (this._positionInEmitterSpace) {\n      node.worldMatrixFromCache.invertToRef(TmpVectors.Matrix[0]);\n      this.setPosition(TmpVectors.Matrix[0].getTranslation());\n    } else {\n      if (!node.getBoundingInfo) {\n        this.setPosition(node.absolutePosition);\n      } else {\n        var mesh = node;\n        var boundingInfo = mesh.getBoundingInfo();\n        this.setPosition(boundingInfo.boundingSphere.centerWorld);\n      }\n    }\n\n    if (Engine.audioEngine.canUseWebAudio && this._isDirectional && this.isPlaying) {\n      this._updateDirection();\n    }\n  };\n  /**\r\n   * Clone the current sound in the scene.\r\n   * @returns the new sound clone\r\n   */\n\n\n  Sound.prototype.clone = function () {\n    var _this = this;\n\n    if (!this._streaming) {\n      var setBufferAndRun = function setBufferAndRun() {\n        if (_this._isReadyToPlay) {\n          clonedSound._audioBuffer = _this.getAudioBuffer();\n          clonedSound._isReadyToPlay = true;\n\n          if (clonedSound.autoplay) {\n            clonedSound.play(0, _this._offset, _this._length);\n          }\n        } else {\n          window.setTimeout(setBufferAndRun, 300);\n        }\n      };\n\n      var currentOptions = {\n        autoplay: this.autoplay,\n        loop: this.loop,\n        volume: this._volume,\n        spatialSound: this.spatialSound,\n        maxDistance: this.maxDistance,\n        useCustomAttenuation: this.useCustomAttenuation,\n        rolloffFactor: this.rolloffFactor,\n        refDistance: this.refDistance,\n        distanceModel: this.distanceModel\n      };\n      var clonedSound = new Sound(this.name + \"_cloned\", new ArrayBuffer(0), this._scene, null, currentOptions);\n\n      if (this.useCustomAttenuation) {\n        clonedSound.setAttenuationFunction(this._customAttenuationFunction);\n      }\n\n      clonedSound.setPosition(this._position);\n      clonedSound.setPlaybackRate(this._playbackRate);\n      setBufferAndRun();\n      return clonedSound;\n    } // Can't clone a streaming sound\n    else {\n      return null;\n    }\n  };\n  /**\r\n   * Gets the current underlying audio buffer containing the data\r\n   * @returns the audio buffer\r\n   */\n\n\n  Sound.prototype.getAudioBuffer = function () {\n    return this._audioBuffer;\n  };\n  /**\r\n   * Gets the WebAudio AudioBufferSourceNode, lets you keep track of and stop instances of this Sound.\r\n   * @returns the source node\r\n   */\n\n\n  Sound.prototype.getSoundSource = function () {\n    return this._soundSource;\n  };\n  /**\r\n   * Gets the WebAudio GainNode, gives you precise control over the gain of instances of this Sound.\r\n   * @returns the gain node\r\n   */\n\n\n  Sound.prototype.getSoundGain = function () {\n    return this._soundGain;\n  };\n  /**\r\n   * Serializes the Sound in a JSON representation\r\n   * @returns the JSON representation of the sound\r\n   */\n\n\n  Sound.prototype.serialize = function () {\n    var serializationObject = {\n      name: this.name,\n      url: this.name,\n      autoplay: this.autoplay,\n      loop: this.loop,\n      volume: this._volume,\n      spatialSound: this.spatialSound,\n      maxDistance: this.maxDistance,\n      rolloffFactor: this.rolloffFactor,\n      refDistance: this.refDistance,\n      distanceModel: this.distanceModel,\n      playbackRate: this._playbackRate,\n      panningModel: this._panningModel,\n      soundTrackId: this.soundTrackId,\n      metadata: this.metadata\n    };\n\n    if (this.spatialSound) {\n      if (this._connectedTransformNode) {\n        serializationObject.connectedMeshId = this._connectedTransformNode.id;\n      }\n\n      serializationObject.position = this._position.asArray();\n      serializationObject.refDistance = this.refDistance;\n      serializationObject.distanceModel = this.distanceModel;\n      serializationObject.isDirectional = this._isDirectional;\n      serializationObject.localDirectionToMesh = this._localDirection.asArray();\n      serializationObject.coneInnerAngle = this._coneInnerAngle;\n      serializationObject.coneOuterAngle = this._coneOuterAngle;\n      serializationObject.coneOuterGain = this._coneOuterGain;\n    }\n\n    return serializationObject;\n  };\n  /**\r\n   * Parse a JSON representation of a sound to innstantiate in a given scene\r\n   * @param parsedSound Define the JSON representation of the sound (usually coming from the serialize method)\r\n   * @param scene Define the scene the new parsed sound should be created in\r\n   * @param rootUrl Define the rooturl of the load in case we need to fetch relative dependencies\r\n   * @param sourceSound Define a cound place holder if do not need to instantiate a new one\r\n   * @returns the newly parsed sound\r\n   */\n\n\n  Sound.Parse = function (parsedSound, scene, rootUrl, sourceSound) {\n    var soundName = parsedSound.name;\n    var soundUrl;\n\n    if (parsedSound.url) {\n      soundUrl = rootUrl + parsedSound.url;\n    } else {\n      soundUrl = rootUrl + soundName;\n    }\n\n    var options = {\n      autoplay: parsedSound.autoplay,\n      loop: parsedSound.loop,\n      volume: parsedSound.volume,\n      spatialSound: parsedSound.spatialSound,\n      maxDistance: parsedSound.maxDistance,\n      rolloffFactor: parsedSound.rolloffFactor,\n      refDistance: parsedSound.refDistance,\n      distanceModel: parsedSound.distanceModel,\n      playbackRate: parsedSound.playbackRate\n    };\n    var newSound;\n\n    if (!sourceSound) {\n      newSound = new Sound(soundName, soundUrl, scene, function () {\n        scene._removePendingData(newSound);\n      }, options);\n\n      scene._addPendingData(newSound);\n    } else {\n      var setBufferAndRun = function setBufferAndRun() {\n        if (sourceSound._isReadyToPlay) {\n          newSound._audioBuffer = sourceSound.getAudioBuffer();\n          newSound._isReadyToPlay = true;\n\n          if (newSound.autoplay) {\n            newSound.play(0, newSound._offset, newSound._length);\n          }\n        } else {\n          window.setTimeout(setBufferAndRun, 300);\n        }\n      };\n\n      newSound = new Sound(soundName, new ArrayBuffer(0), scene, null, options);\n      setBufferAndRun();\n    }\n\n    if (parsedSound.position) {\n      var soundPosition = Vector3.FromArray(parsedSound.position);\n      newSound.setPosition(soundPosition);\n    }\n\n    if (parsedSound.isDirectional) {\n      newSound.setDirectionalCone(parsedSound.coneInnerAngle || 360, parsedSound.coneOuterAngle || 360, parsedSound.coneOuterGain || 0);\n\n      if (parsedSound.localDirectionToMesh) {\n        var localDirectionToMesh = Vector3.FromArray(parsedSound.localDirectionToMesh);\n        newSound.setLocalDirectionToMesh(localDirectionToMesh);\n      }\n    }\n\n    if (parsedSound.connectedMeshId) {\n      var connectedMesh = scene.getMeshByID(parsedSound.connectedMeshId);\n\n      if (connectedMesh) {\n        newSound.attachToMesh(connectedMesh);\n      }\n    }\n\n    if (parsedSound.metadata) {\n      newSound.metadata = parsedSound.metadata;\n    }\n\n    return newSound;\n  };\n  /** @hidden */\n\n\n  Sound._SceneComponentInitialization = function (_) {\n    throw _DevTools.WarnImport(\"AudioSceneComponent\");\n  };\n\n  return Sound;\n}();\n\nexport { Sound };","map":null,"metadata":{},"sourceType":"module"}