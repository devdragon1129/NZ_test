{"ast":null,"code":"import { Observable } from \"../Misc/observable\";\nimport { Logger } from \"../Misc/logger\";\nimport { Engine } from \"../Engines/engine\"; // Sets the default audio engine to Babylon.js\n\nEngine.AudioEngineFactory = function (hostElement) {\n  return new AudioEngine(hostElement);\n};\n/**\r\n * This represents the default audio engine used in babylon.\r\n * It is responsible to play, synchronize and analyse sounds throughout the  application.\r\n * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music\r\n */\n\n\nvar AudioEngine =\n/** @class */\nfunction () {\n  /**\r\n   * Instantiates a new audio engine.\r\n   *\r\n   * There should be only one per page as some browsers restrict the number\r\n   * of audio contexts you can create.\r\n   * @param hostElement defines the host element where to display the mute icon if necessary\r\n   */\n  function AudioEngine(hostElement) {\n    var _this = this;\n\n    if (hostElement === void 0) {\n      hostElement = null;\n    }\n\n    this._audioContext = null;\n    this._audioContextInitialized = false;\n    this._muteButton = null;\n    /**\r\n     * Gets whether the current host supports Web Audio and thus could create AudioContexts.\r\n     */\n\n    this.canUseWebAudio = false;\n    /**\r\n     * Defines if Babylon should emit a warning if WebAudio is not supported.\r\n     * @ignoreNaming\r\n     */\n\n    this.WarnedWebAudioUnsupported = false;\n    /**\r\n     * Gets whether or not mp3 are supported by your browser.\r\n     */\n\n    this.isMP3supported = false;\n    /**\r\n     * Gets whether or not ogg are supported by your browser.\r\n     */\n\n    this.isOGGsupported = false;\n    /**\r\n     * Gets whether audio has been unlocked on the device.\r\n     * Some Browsers have strong restrictions about Audio and won t autoplay unless\r\n     * a user interaction has happened.\r\n     */\n\n    this.unlocked = true;\n    /**\r\n     * Defines if the audio engine relies on a custom unlocked button.\r\n     * In this case, the embedded button will not be displayed.\r\n     */\n\n    this.useCustomUnlockedButton = false;\n    /**\r\n     * Event raised when audio has been unlocked on the browser.\r\n     */\n\n    this.onAudioUnlockedObservable = new Observable();\n    /**\r\n     * Event raised when audio has been locked on the browser.\r\n     */\n\n    this.onAudioLockedObservable = new Observable();\n    this._tryToRun = false;\n\n    this._onResize = function () {\n      _this._moveButtonToTopLeft();\n    };\n\n    if (typeof window.AudioContext !== 'undefined' || typeof window.webkitAudioContext !== 'undefined') {\n      window.AudioContext = window.AudioContext || window.webkitAudioContext;\n      this.canUseWebAudio = true;\n    }\n\n    var audioElem = document.createElement('audio');\n    this._hostElement = hostElement;\n\n    try {\n      if (audioElem && !!audioElem.canPlayType && (audioElem.canPlayType('audio/mpeg; codecs=\"mp3\"').replace(/^no$/, '') || audioElem.canPlayType('audio/mp3').replace(/^no$/, ''))) {\n        this.isMP3supported = true;\n      }\n    } catch (e) {// protect error during capability check.\n    }\n\n    try {\n      if (audioElem && !!audioElem.canPlayType && audioElem.canPlayType('audio/ogg; codecs=\"vorbis\"').replace(/^no$/, '')) {\n        this.isOGGsupported = true;\n      }\n    } catch (e) {// protect error during capability check.\n    }\n  }\n\n  Object.defineProperty(AudioEngine.prototype, \"audioContext\", {\n    /**\r\n     * Gets the current AudioContext if available.\r\n     */\n    get: function get() {\n      if (!this._audioContextInitialized) {\n        this._initializeAudioContext();\n      } else {\n        if (!this.unlocked && !this._muteButton) {\n          this._displayMuteButton();\n        }\n      }\n\n      return this._audioContext;\n    },\n    enumerable: false,\n    configurable: true\n  });\n  /**\r\n   * Flags the audio engine in Locked state.\r\n   * This happens due to new browser policies preventing audio to autoplay.\r\n   */\n\n  AudioEngine.prototype.lock = function () {\n    this._triggerSuspendedState();\n  };\n  /**\r\n   * Unlocks the audio engine once a user action has been done on the dom.\r\n   * This is helpful to resume play once browser policies have been satisfied.\r\n   */\n\n\n  AudioEngine.prototype.unlock = function () {\n    this._triggerRunningState();\n  };\n\n  AudioEngine.prototype._resumeAudioContext = function () {\n    var result;\n\n    if (this._audioContext.resume !== undefined) {\n      result = this._audioContext.resume();\n    }\n\n    return result || Promise.resolve();\n  };\n\n  AudioEngine.prototype._initializeAudioContext = function () {\n    try {\n      if (this.canUseWebAudio) {\n        this._audioContext = new AudioContext(); // create a global volume gain node\n\n        this.masterGain = this._audioContext.createGain();\n        this.masterGain.gain.value = 1;\n        this.masterGain.connect(this._audioContext.destination);\n        this._audioContextInitialized = true;\n\n        if (this._audioContext.state === \"running\") {\n          // Do not wait for the promise to unlock.\n          this._triggerRunningState();\n        }\n      }\n    } catch (e) {\n      this.canUseWebAudio = false;\n      Logger.Error(\"Web Audio: \" + e.message);\n    }\n  };\n\n  AudioEngine.prototype._triggerRunningState = function () {\n    var _this = this;\n\n    if (this._tryToRun) {\n      return;\n    }\n\n    this._tryToRun = true;\n\n    this._resumeAudioContext().then(function () {\n      _this._tryToRun = false;\n\n      if (_this._muteButton) {\n        _this._hideMuteButton();\n      } // Notify users that the audio stack is unlocked/unmuted\n\n\n      _this.unlocked = true;\n\n      _this.onAudioUnlockedObservable.notifyObservers(_this);\n    }).catch(function () {\n      _this._tryToRun = false;\n      _this.unlocked = false;\n    });\n  };\n\n  AudioEngine.prototype._triggerSuspendedState = function () {\n    this.unlocked = false;\n    this.onAudioLockedObservable.notifyObservers(this);\n\n    this._displayMuteButton();\n  };\n\n  AudioEngine.prototype._displayMuteButton = function () {\n    var _this = this;\n\n    if (this.useCustomUnlockedButton || this._muteButton) {\n      return;\n    }\n\n    this._muteButton = document.createElement(\"BUTTON\");\n    this._muteButton.className = \"babylonUnmuteIcon\";\n    this._muteButton.id = \"babylonUnmuteIconBtn\";\n    this._muteButton.title = \"Unmute\";\n    var imageUrl = !window.SVGSVGElement ? \"https://cdn.babylonjs.com/Assets/audio.png\" : \"data:image/svg+xml;charset=UTF-8,%3Csvg%20version%3D%221.1%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2239%22%20height%3D%2232%22%20viewBox%3D%220%200%2039%2032%22%3E%3Cpath%20fill%3D%22white%22%20d%3D%22M9.625%2018.938l-0.031%200.016h-4.953q-0.016%200-0.031-0.016v-12.453q0-0.016%200.031-0.016h4.953q0.031%200%200.031%200.016v12.453zM12.125%207.688l8.719-8.703v27.453l-8.719-8.719-0.016-0.047v-9.938zM23.359%207.875l1.406-1.406%204.219%204.203%204.203-4.203%201.422%201.406-4.219%204.219%204.219%204.203-1.484%201.359-4.141-4.156-4.219%204.219-1.406-1.422%204.219-4.203z%22%3E%3C%2Fpath%3E%3C%2Fsvg%3E\";\n    var css = \".babylonUnmuteIcon { position: absolute; left: 20px; top: 20px; height: 40px; width: 60px; background-color: rgba(51,51,51,0.7); background-image: url(\" + imageUrl + \");  background-size: 80%; background-repeat:no-repeat; background-position: center; background-position-y: 4px; border: none; outline: none; transition: transform 0.125s ease-out; cursor: pointer; z-index: 9999; } .babylonUnmuteIcon:hover { transform: scale(1.05) } .babylonUnmuteIcon:active { background-color: rgba(51,51,51,1) }\";\n    var style = document.createElement('style');\n    style.appendChild(document.createTextNode(css));\n    document.getElementsByTagName('head')[0].appendChild(style);\n    document.body.appendChild(this._muteButton);\n\n    this._moveButtonToTopLeft();\n\n    this._muteButton.addEventListener('touchend', function () {\n      _this._triggerRunningState();\n    }, true);\n\n    this._muteButton.addEventListener('click', function () {\n      _this._triggerRunningState();\n    }, true);\n\n    window.addEventListener(\"resize\", this._onResize);\n  };\n\n  AudioEngine.prototype._moveButtonToTopLeft = function () {\n    if (this._hostElement && this._muteButton) {\n      this._muteButton.style.top = this._hostElement.offsetTop + 20 + \"px\";\n      this._muteButton.style.left = this._hostElement.offsetLeft + 20 + \"px\";\n    }\n  };\n\n  AudioEngine.prototype._hideMuteButton = function () {\n    if (this._muteButton) {\n      document.body.removeChild(this._muteButton);\n      this._muteButton = null;\n    }\n  };\n  /**\r\n   * Destroy and release the resources associated with the audio ccontext.\r\n   */\n\n\n  AudioEngine.prototype.dispose = function () {\n    if (this.canUseWebAudio && this._audioContextInitialized) {\n      if (this._connectedAnalyser && this._audioContext) {\n        this._connectedAnalyser.stopDebugCanvas();\n\n        this._connectedAnalyser.dispose();\n\n        this.masterGain.disconnect();\n        this.masterGain.connect(this._audioContext.destination);\n        this._connectedAnalyser = null;\n      }\n\n      this.masterGain.gain.value = 1;\n    }\n\n    this.WarnedWebAudioUnsupported = false;\n\n    this._hideMuteButton();\n\n    window.removeEventListener(\"resize\", this._onResize);\n    this.onAudioUnlockedObservable.clear();\n    this.onAudioLockedObservable.clear();\n  };\n  /**\r\n   * Gets the global volume sets on the master gain.\r\n   * @returns the global volume if set or -1 otherwise\r\n   */\n\n\n  AudioEngine.prototype.getGlobalVolume = function () {\n    if (this.canUseWebAudio && this._audioContextInitialized) {\n      return this.masterGain.gain.value;\n    } else {\n      return -1;\n    }\n  };\n  /**\r\n   * Sets the global volume of your experience (sets on the master gain).\r\n   * @param newVolume Defines the new global volume of the application\r\n   */\n\n\n  AudioEngine.prototype.setGlobalVolume = function (newVolume) {\n    if (this.canUseWebAudio && this._audioContextInitialized) {\n      this.masterGain.gain.value = newVolume;\n    }\n  };\n  /**\r\n   * Connect the audio engine to an audio analyser allowing some amazing\r\n   * synchornization between the sounds/music and your visualization (VuMeter for instance).\r\n   * @see https://doc.babylonjs.com/how_to/playing_sounds_and_music#using-the-analyser\r\n   * @param analyser The analyser to connect to the engine\r\n   */\n\n\n  AudioEngine.prototype.connectToAnalyser = function (analyser) {\n    if (this._connectedAnalyser) {\n      this._connectedAnalyser.stopDebugCanvas();\n    }\n\n    if (this.canUseWebAudio && this._audioContextInitialized && this._audioContext) {\n      this._connectedAnalyser = analyser;\n      this.masterGain.disconnect();\n\n      this._connectedAnalyser.connectAudioNodes(this.masterGain, this._audioContext.destination);\n    }\n  };\n\n  return AudioEngine;\n}();\n\nexport { AudioEngine };","map":null,"metadata":{},"sourceType":"module"}